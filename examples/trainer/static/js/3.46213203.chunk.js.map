{"version":3,"sources":["../../../../lib/wasm/rust_wasm_tensor_bg.js","../node_modules/webpack/buildin/harmony-module.js","../../../../lib/wasm/rust_wasm_tensor.js"],"names":["heap","ret","TensorF32","__wrap","this","ptr","_assertClass","kernel","other","TensorF64","TensorI16","TensorI32","shape","TensorI8","TensorU16","TensorU32","TensorU8","getObject","arg0","length","addHeapObject","arg1","arg2","module","exports","originalModule","webpackPolyfill","Object","create","children","defineProperty","enumerable","get","l","i"],"mappings":"iGAAA,86CAEM,EAAO,IAAI,MAAM,IAAI,UAAK,GAIhC,SAAS,EAAU,GAAO,OAAO,EAAK,GAFtC,EAAK,UAAK,EAAW,MAAM,GAAM,GAIjC,IAAI,EAAYA,EAAK,OAQrB,SAAS,EAAW,GAChB,IAAM,EAAM,EAAU,GAEtB,OATJ,SAAoB,GACZ,EAAM,KACV,EAAK,GAAO,EACZ,EAAY,GAKZ,CAAW,GACJ,EAGX,IAEI,EAAoB,IAFoB,qBAAhB,aAA8B,EAAI,EAAO,SAAS,QAAQ,YAAc,aAE3D,QAAS,CAAE,WAAW,EAAM,OAAO,IAE5E,EAAkB,SAElB,IAAI,EAAuB,KAQ3B,SAAS,EAAmB,EAAK,GAC7B,OAAO,EAAkB,QAPI,OAAzB,GAAiC,EAAqB,SAAW,IAAY,SAC7E,EAAuB,IAAI,WAAW,IAAY,SAE/C,GAI2C,SAAS,EAAK,EAAM,IAG1E,SAAS,EAAc,GACf,IAAc,EAAK,QAAQ,EAAK,KAAK,EAAK,OAAS,GACvD,IAAM,EAAM,EAIZ,OAHA,EAAY,EAAK,GAEjB,EAAK,GAAO,EACL,EAGX,SAAS,EAAa,EAAU,GAC1B,KAAI,aAAoB,GACtB,MAAM,IAAI,MAAM,wBAAwB,EAAM,MAElD,OAAO,EAAS,IAIpB,iBAAE,SAAF,KA8nBE,OA5nBS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,IAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAIC,EAAM,IAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5BC,EAAA,8BAEI,OAAO,EADG,IAAwB,KAAK,OAM3CA,EAAA,+BAEI,OAAO,EADG,IAAyB,KAAK,OAM5CA,EAAA,yBACI,IAAID,EAAM,IAAmB,KAAK,KAClC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,yBACI,IAAID,EAAM,IAAmBG,KAAKC,KAClC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,KAAoB,KAAK,KACnC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,yBACI,IAAID,EAAM,KAAmBG,KAAKC,KAClC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,yBACI,IAAID,EAAM,IAAmB,KAAK,KAClC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,yBACI,IAAID,EAAM,KAAmB,KAAK,KAClC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,IAAoBG,KAAKC,KACnC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,IAAoBG,KAAKC,KACnC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,IAAoBG,KAAKC,KACnC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,KAAoBG,KAAKC,KACnC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,IAAoB,KAAK,KACnC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,0BACI,IAAID,EAAM,KAAoB,KAAK,KACnC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,2BACI,IAAID,EAAM,IAAqBG,KAAKC,KACpC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,2BACI,IAAID,EAAM,IAAqB,KAAK,KACpC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,2BACI,IAAID,EAAM,IAAqBG,KAAKC,KACpC,OAAOH,EAAUC,OAAOF,IAK5BC,EAAA,6BACI,IAAID,EAAM,KAAuB,KAAK,KACtC,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,2BACI,IAAID,EAAM,IAAqBG,KAAKC,KACpC,OAAOH,EAAUC,OAAOF,IAK5B,4BACI,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,6BACI,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,IAO5B,kCAAa,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,IAO5BC,EAAA,gCAAa,EAAO,GAChB,IAAID,EAAM,IAA4B,KAAK,IAAK,EAAO,GACvD,OAAOC,EAAUC,OAAOF,IAK5BC,EAAA,yBACI,IAAID,EAAM,IAAmB,KAAK,KAClC,OAAOC,EAAUC,OAAOF,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,8BACI,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,IAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,IAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,IAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,2BAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAM5B,yBAAI,GACA,EAAa,EAAO,GACpB,IAAI,EAAM,IAAmB,KAAK,IAAK,EAAM,KAC7C,OAAO,EAAU,OAAO,IAM1B,EAAF,4BAAS,GACL,EAAa,EAAO,GACpB,IAAI,EAAM,IAAwB,KAAK,IAAK,EAAM,KAClD,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,IAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,IAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,IAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,IAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,IAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,IAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,IAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO5B,wCAAmB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,IAO5B,oCAAe,EAAM,GACjB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAO,GACvE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOC,EAAUC,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5BC,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DI,EAAaC,EAAQL,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,IAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,IAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,IAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM1B,EAAF,4BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAU1B,EAAF,6BAAU,EAAM,EAAU,EAAS,EAAO,GACtC,EAAa,EAAM,GACnB,EAAa,EAAU,GACvB,EAAa,EAAO,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAK,IAAK,EAAS,IAAK,EAAS,EAAM,IAAK,EAAK,KAC9F,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCI,EAAaE,EAAON,GACpB,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,IAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EA9nBA,GAioBA,aAAE,SAAF,KA8nBE,OA5nBS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAID,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5BQ,EAAA,8BAEI,OAAO,EADG,KAAwB,KAAK,OAM3CA,EAAA,+BAEI,OAAO,EADG,KAAyB,KAAK,OAM5CA,EAAA,yBACI,IAAIR,EAAM,KAAmB,KAAK,KAClC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,yBACI,IAAIR,EAAM,KAAmBG,KAAKC,KAClC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoB,KAAK,KACnC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,yBACI,IAAIR,EAAM,KAAmBG,KAAKC,KAClC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,yBACI,IAAIR,EAAM,KAAmB,KAAK,KAClC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,yBACI,IAAIR,EAAM,KAAmB,KAAK,KAClC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoBG,KAAKC,KACnC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoBG,KAAKC,KACnC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoBG,KAAKC,KACnC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoBG,KAAKC,KACnC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoB,KAAK,KACnC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,0BACI,IAAIR,EAAM,KAAoB,KAAK,KACnC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,2BACI,IAAIR,EAAM,KAAqBG,KAAKC,KACpC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,2BACI,IAAIR,EAAM,KAAqB,KAAK,KACpC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,2BACI,IAAIR,EAAM,KAAqBG,KAAKC,KACpC,OAAOI,EAAUN,OAAOF,IAK5BQ,EAAA,6BACI,IAAIR,EAAM,KAAuB,KAAK,KACtC,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,2BACI,IAAIR,EAAM,KAAqBG,KAAKC,KACpC,OAAOI,EAAUN,OAAOF,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,6BACI,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,IAO5B,kCAAa,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,IAO5BQ,EAAA,gCAAa,EAAO,GAChB,IAAIR,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAOQ,EAAUN,OAAOF,IAK5BQ,EAAA,yBACI,IAAIR,EAAM,KAAmB,KAAK,KAClC,OAAOQ,EAAUN,OAAOF,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,8BACI,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,2BAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAM5B,yBAAI,GACA,EAAa,EAAO,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,KAC7C,OAAO,EAAU,OAAO,IAM1B,EAAF,4BAAS,GACL,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,KAClD,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO5B,wCAAmB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,IAO5B,oCAAe,EAAM,GACjB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAO,GACvE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOQ,EAAUN,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5BQ,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DH,EAAaC,EAAQE,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM1B,EAAF,4BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAU1B,EAAF,6BAAU,EAAM,EAAU,EAAS,EAAO,GACtC,EAAa,EAAM,GACnB,EAAa,EAAU,GACvB,EAAa,EAAO,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAK,IAAK,EAAS,IAAK,EAAS,EAAM,IAAK,EAAK,KAC9F,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCH,EAAaE,EAAOC,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EA9nBA,GAioBA,aAAE,SAAF,KA4bE,OA1bS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAIR,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5B,gCAEI,OAAO,EADG,KAAwB,KAAK,OAM3C,iCAEI,OAAO,EADG,KAAyB,KAAK,OAQ5CS,EAAA,gCAAa,EAAO,GAChB,IAAIT,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAOS,EAAUP,OAAOF,IAK5BS,EAAA,yBACI,IAAIT,EAAM,KAAmB,KAAK,KAClC,OAAOS,EAAUP,OAAOF,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,8BACI,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM1B,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOS,EAAUP,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5BS,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DJ,EAAaC,EAAQG,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCJ,EAAaE,EAAOE,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EA5bA,GA+bA,aAAE,SAAF,KA4bE,OA1bS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAIT,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5B,gCAEI,OAAO,EADG,KAAwB,KAAK,OAM3C,iCAEI,OAAO,EADG,KAAyB,KAAK,OAQ5CU,EAAA,gCAAa,EAAO,GAChB,IAAIV,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAOU,EAAUR,OAAOF,IAK5BU,EAAA,yBACI,IAAIV,EAAM,KAAmB,KAAK,KAClC,OAAOU,EAAUR,OAAOF,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAK5B,8BACI,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM1B,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOU,EAAUR,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5BU,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DL,EAAaC,EAAQI,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCL,EAAaE,EAAOG,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EA5bA,GA+bA,aAAE,SAAF,KA4bE,OA1bS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAS,WAGnC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAAyB,IAOtB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAqB,EAAc,GAAQ,EAAc,IACnE,OAAO,EAAS,OAAO,IAOpB,kBAAP,SAAuBC,EAAO,GAC1B,IAAIX,EAAM,KAA8B,EAAc,GAAQ,GAC9D,OAAO,EAAS,OAAO,IAK3B,gCAEI,OAAO,EADG,KAAuB,KAAK,OAM1C,iCAEI,OAAO,EADG,KAAwB,KAAK,OAQ3CY,EAAA,gCAAa,EAAO,GAChB,IAAIZ,EAAM,KAA2B,KAAK,IAAK,EAAO,GACtD,OAAOY,EAASV,OAAOF,IAK3BY,EAAA,yBACI,IAAIZ,EAAM,KAAkB,KAAK,KACjC,OAAOY,EAASV,OAAOF,IAK3B,4BACI,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,IAK3B,8BACI,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAS,OAAO,IAO3B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,GAC9D,OAAO,EAAS,OAAO,IAO3B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAK,GAC5C,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,IAMzB,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,KAC9C,OAAO,EAAS,OAAO,IAQzB,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC7D,OAAO,EAAS,OAAO,IAQ3B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAO,GAChE,OAAO,EAAS,OAAO,IAO3B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,GACtD,OAAO,EAAS,OAAO,IAOzB,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,IAQ3B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAK,EAAK,EAAK,KAC/D,OAAO,EAAS,OAAO,IAO3B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,IAO3B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,gCAAW,EAAM,GACb,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAO,GAClE,OAAO,EAAS,OAAO,IAO3B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,GAAO,GAC/D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAS,OAAO,IAOzB,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAO,GAC1E,OAAOY,EAASV,OAAOF,IAW3B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACjI,OAAO,EAAS,OAAO,IAY3BY,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DP,EAAaC,EAAQM,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACrJ,OAAO,EAAS,OAAO,IAUzB,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IACjI,OAAO,EAAS,OAAO,IAS3B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GACzH,OAAO,EAAS,OAAO,IAQ3B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,EAAM,GACjE,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAS,OAAO,IAMzB,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAS,OAAO,IAS3BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCP,EAAaE,EAAOK,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC5E,OAAO,EAAS,OAAO,IAWzB,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GACjG,OAAO,EAAS,OAAO,IAO3B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAO,IAAK,EAAc,IACvE,OAAO,EAAS,OAAO,IAM3B,6BAAQ,GACJ,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAS,OAAO,IAO3B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,IAM3B,+BAAU,GACN,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAS,OAAO,IAM3B,4BAAO,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,IAM3B,4BAAO,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,IAK3B,4BACI,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,IAQ3B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACrF,OAAO,EAAS,OAAO,IASzB,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACvH,OAAO,EAAS,OAAO,IAE/B,EA5bA,GA+bA,aAAE,SAAF,KAuaE,OAraS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAIZ,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5B,gCAEI,OAAO,EADG,KAAwB,KAAK,OAM3C,iCAEI,OAAO,EADG,KAAyB,KAAK,OAQ5C,kCAAa,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM1B,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOa,EAAUX,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5Ba,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DR,EAAaC,EAAQO,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCR,EAAaE,EAAOM,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EAvaA,GA0aA,aAAE,SAAF,KAuaE,OAraS,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAA0B,IAOvB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,IAOrB,kBAAP,SAAuB,EAAO,GAC1B,IAAIb,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,IAK5B,gCAEI,OAAO,EADG,KAAwB,KAAK,OAM3C,iCAEI,OAAO,EADG,KAAyB,KAAK,OAQ5C,kCAAa,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,IAO5B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,IAO5B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,IAM1B,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,IAQ1B,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,IAQ5B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,IAO5B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,IAO1B,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAQ5B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,IAO5B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,IAO5B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,IAO1B,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAOc,EAAUZ,OAAOF,IAW5B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,IAY5Bc,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DT,EAAaC,EAAQQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,IAU1B,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,IAS5B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,IAQ5B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,IAM5B,8BAAS,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,IAM1B,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,IAS5BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCT,EAAaE,EAAOO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,IAW1B,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,IAO5B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,IAM5B,6BAAQ,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,IAO5B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,IAM5B,+BAAU,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAM5B,4BAAO,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,IAK5B,4BACI,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,IAQ5B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,IAS1B,EAAF,yBAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,IAEhC,EAvaA,GA0aA,aAAE,SAAF,KAuaA,OAraW,SAAP,SAAc,GACV,IAAM,EAAM,OAAO,OAAO,EAAS,WAGnC,OAFA,EAAI,IAAM,EAEH,GAGX,4BACI,IAAM,EAAM,KAAK,IACjB,KAAK,IAAM,EAEX,IAAyB,IAOtB,SAAP,SAAc,EAAO,GACjB,IAAI,EAAM,KAAqB,EAAc,GAAQ,EAAc,IACnE,OAAO,EAAS,OAAO,IAOpB,kBAAP,SAAuBH,EAAO,GAC1B,IAAIX,EAAM,KAA8B,EAAc,GAAQ,GAC9D,OAAO,EAAS,OAAO,IAK3B,gCAEI,OAAO,EADG,KAAuB,KAAK,OAM1C,iCAEI,OAAO,EADG,KAAwB,KAAK,OAQ3C,kCAAa,EAAO,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAO,GACtD,OAAO,EAAS,OAAO,IAO3B,yCAAoB,EAAQ,GACxB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,GAC9D,OAAO,EAAS,OAAO,IAO3B,0BAAK,EAAK,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAK,GAC5C,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,IAMzB,EAAF,yBAAM,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,KAC9C,OAAO,EAAS,OAAO,IAQzB,EAAF,4BAAS,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC7D,OAAO,EAAS,OAAO,IAQ3B,iCAAY,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAO,GAChE,OAAO,EAAS,OAAO,IAO3B,8BAAS,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,GACtD,OAAO,EAAS,OAAO,IAOzB,EAAF,0BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,IAQ3B,mCAAc,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAK,EAAK,EAAK,KAC/D,OAAO,EAAS,OAAO,IAO3B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,IAO3B,uCAAkB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,gCAAW,EAAM,GACb,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAO,GAClE,OAAO,EAAS,OAAO,IAO3B,6BAAQ,EAAM,GACV,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,GAAO,GAC/D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,yBAAI,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,IAO3B,iCAAY,EAAM,GACd,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAS,OAAO,IAOzB,EAAF,sCAAmB,EAAM,GACrB,IAAIA,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAO,GAC1E,OAAOe,EAASb,OAAOF,IAW3B,0BAAK,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACjI,OAAO,EAAS,OAAO,IAY3Be,EAAA,kCAAe,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DV,EAAaC,EAAQS,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACrJ,OAAO,EAAS,OAAO,IAUzB,EAAF,kCAAe,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IACjI,OAAO,EAAS,OAAO,IAS3B,kCAAa,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GACzH,OAAO,EAAS,OAAO,IAQ3B,yBAAI,EAAM,EAAM,GACZ,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,EAAM,GACjE,OAAO,EAAS,OAAO,IAM3B,8BAAS,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAS,OAAO,IAMzB,EAAF,0BAAO,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAS,OAAO,IAS3BA,EAAA,wBAAK,EAAO,EAAa,EAAa,GAClCV,EAAaE,EAAOQ,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC5E,OAAO,EAAS,OAAO,IAWzB,EAAF,+BAAY,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GACjG,OAAO,EAAS,OAAO,IAO3B,gCAAW,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAO,IAAK,EAAc,IACvE,OAAO,EAAS,OAAO,IAM3B,6BAAQ,GACJ,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAS,OAAO,IAO3B,4BAAO,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,IAM3B,+BAAU,GACN,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAS,OAAO,IAM3B,4BAAO,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,IAM3B,4BAAO,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,IAK3B,4BACI,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,IAQ3B,4BAAO,EAAM,EAAS,GAClB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACrF,OAAO,EAAS,OAAO,IAS3B,2BAAM,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACvH,OAAO,EAAS,OAAO,IAE/B,EAvaA,GAyaa,EAA6B,SAAS,GAC/C,EAAW,IAGF,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADUC,EAAUC,GAAMC,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAuC,SAAS,GAEzD,OAAOC,EADG,IAAI,UAAU,IAAS,KAIxB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChEH,EAAUC,GAAMG,IAAS,GAAKC,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,YAAY,IAAS,KAI1B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,YAAY,IAAS,KAI1B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,IAAS,GAG9B,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,aAAa,IAAS,KAI3B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,aAAa,IAAS,KAI3B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,GAAmB,SAAS,EAAM,GAC3C,MAAM,IAAI,MAAM,EAAmB,EAAM,O,wCClhI7CC,EAAOC,QAAU,SAASC,GACzB,IAAKA,EAAeC,gBAAiB,CACpC,IAAIH,EAASI,OAAOC,OAAOH,GAEtBF,EAAOM,WAAUN,EAAOM,SAAW,IACxCF,OAAOG,eAAeP,EAAQ,SAAU,CACvCQ,YAAY,EACZC,IAAK,WACJ,OAAOT,EAAOU,KAGhBN,OAAOG,eAAeP,EAAQ,KAAM,CACnCQ,YAAY,EACZC,IAAK,WACJ,OAAOT,EAAOW,KAGhBP,OAAOG,eAAeP,EAAQ,UAAW,CACxCQ,YAAY,IAEbR,EAAOG,gBAAkB,EAE1B,OAAOH,I,4GCrBR","file":"static/js/3.46213203.chunk.js","sourcesContent":["import * as wasm from './rust_wasm_tensor_bg.wasm';\nvar heap = new Array(32).fill(undefined);\nheap.push(undefined, null, true, false);\nfunction getObject(idx) { return heap[idx]; }\nvar heap_next = heap.length;\nfunction dropObject(idx) {\n    if (idx < 36)\n        return;\n    heap[idx] = heap_next;\n    heap_next = idx;\n}\nfunction takeObject(idx) {\n    var ret = getObject(idx);\n    dropObject(idx);\n    return ret;\n}\nvar lTextDecoder = typeof TextDecoder === 'undefined' ? (0, module.require)('util').TextDecoder : TextDecoder;\nvar cachedTextDecoder = new lTextDecoder('utf-8', { ignoreBOM: true, fatal: true });\ncachedTextDecoder.decode();\nvar cachegetUint8Memory0 = null;\nfunction getUint8Memory0() {\n    if (cachegetUint8Memory0 === null || cachegetUint8Memory0.buffer !== wasm.memory.buffer) {\n        cachegetUint8Memory0 = new Uint8Array(wasm.memory.buffer);\n    }\n    return cachegetUint8Memory0;\n}\nfunction getStringFromWasm0(ptr, len) {\n    return cachedTextDecoder.decode(getUint8Memory0().subarray(ptr, ptr + len));\n}\nfunction addHeapObject(obj) {\n    if (heap_next === heap.length)\n        heap.push(heap.length + 1);\n    var idx = heap_next;\n    heap_next = heap[idx];\n    heap[idx] = obj;\n    return idx;\n}\nfunction _assertClass(instance, klass) {\n    if (!(instance instanceof klass)) {\n        throw new Error(\"expected instance of \" + klass.name);\n    }\n    return instance.ptr;\n}\n/**\n*/\nvar TensorF32 = /** @class */ (function () {\n    function TensorF32() {\n    }\n    TensorF32.__wrap = function (ptr) {\n        var obj = Object.create(TensorF32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorF32.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensorf32_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Float32Array} values\n    * @returns {TensorF32}\n    */\n    TensorF32.create = function (shape, values) {\n        var ret = wasm.tensorf32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorF32}\n    */\n    TensorF32.create_constant = function (shape, value) {\n        var ret = wasm.tensorf32_create_constant(addHeapObject(shape), value);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {Float32Array}\n    */\n    TensorF32.prototype.get_vals = function () {\n        var ret = wasm.tensorf32_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorF32.prototype.get_shape = function () {\n        var ret = wasm.tensorf32_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.exp = function () {\n        var ret = wasm.tensorf32_exp(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.log = function () {\n        var ret = wasm.tensorf32_log(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sqrt = function () {\n        var ret = wasm.tensorf32_sqrt(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sin = function () {\n        var ret = wasm.tensorf32_sin(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.cos = function () {\n        var ret = wasm.tensorf32_cos(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.tan = function () {\n        var ret = wasm.tensorf32_tan(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.asin = function () {\n        var ret = wasm.tensorf32_asin(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.acos = function () {\n        var ret = wasm.tensorf32_acos(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.atan = function () {\n        var ret = wasm.tensorf32_atan(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sinh = function () {\n        var ret = wasm.tensorf32_sinh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.cosh = function () {\n        var ret = wasm.tensorf32_cosh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.tanh = function () {\n        var ret = wasm.tensorf32_tanh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.asinh = function () {\n        var ret = wasm.tensorf32_asinh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.acosh = function () {\n        var ret = wasm.tensorf32_acosh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.atanh = function () {\n        var ret = wasm.tensorf32_atanh(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sigmoid = function () {\n        var ret = wasm.tensorf32_sigmoid(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.floor = function () {\n        var ret = wasm.tensorf32_floor(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.ceil = function () {\n        var ret = wasm.tensorf32_ceil(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.round = function () {\n        var ret = wasm.tensorf32_round(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensorf32_power_scalar(this.ptr, power, factor);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.hard_sigmoid = function (alpha, beta) {\n        var ret = wasm.tensorf32_hard_sigmoid(this.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.abs = function () {\n        var ret = wasm.tensorf32_abs(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sign = function () {\n        var ret = wasm.tensorf32_sign(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.negate = function () {\n        var ret = wasm.tensorf32_negate(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensorf32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip = function (min, max) {\n        var ret = wasm.tensorf32_clip(this.ptr, min, max);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip_min = function (min) {\n        var ret = wasm.tensorf32_clip_min(this.ptr, min);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip_max = function (max) {\n        var ret = wasm.tensorf32_clip_max(this.ptr, max);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.power = function (other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_power(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.bce = function (other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_bce(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.bce_back = function (other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_bce_back(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_multiply(this.ptr, other.ptr, alpha);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_divide(this.ptr, other.ptr, alpha);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.reduce_log_sum = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_log_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.reduce_log_sum_exp = function (axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_log_sum_exp(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF32);\n        var ret = wasm.tensorf32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} kernel\n    * @param {TensorF32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF32);\n        _assertClass(bias, TensorF32);\n        var ret = wasm.tensorf32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorF32);\n        var ret = wasm.tensorf32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensorf32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensorf32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.upsample = function (scales) {\n        var ret = wasm.tensorf32_upsample(this.ptr, addHeapObject(scales));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} mean\n    * @param {TensorF32} variance\n    * @param {number} epsilon\n    * @param {TensorF32} scale\n    * @param {TensorF32} bias\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.normalize = function (mean, variance, epsilon, scale, bias) {\n        _assertClass(mean, TensorF32);\n        _assertClass(variance, TensorF32);\n        _assertClass(scale, TensorF32);\n        _assertClass(bias, TensorF32);\n        var ret = wasm.tensorf32_normalize(this.ptr, mean.ptr, variance.ptr, epsilon, scale.ptr, bias.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.matmul = function (other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_matmul(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorF32} c\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorF32);\n        _assertClass(c, TensorF32);\n        var ret = wasm.tensorf32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorF32);\n        var ret = wasm.tensorf32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.reshape = function (shape) {\n        var ret = wasm.tensorf32_reshape(this.ptr, addHeapObject(shape));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {TensorF32} other\n    * @param {number} axes\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_concat(this.ptr, other.ptr, axes);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.transpose = function (permutation) {\n        var ret = wasm.tensorf32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.repeat = function (repeats) {\n        var ret = wasm.tensorf32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.expand = function (shape) {\n        var ret = wasm.tensorf32_expand(this.ptr, addHeapObject(shape));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.copy = function () {\n        var ret = wasm.tensorf32_copy(this.ptr);\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensorf32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorF32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorF32}\n    */\n    TensorF32.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensorf32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorF32.__wrap(ret);\n    };\n    return TensorF32;\n}());\nexport { TensorF32 };\n/**\n*/\nvar TensorF64 = /** @class */ (function () {\n    function TensorF64() {\n    }\n    TensorF64.__wrap = function (ptr) {\n        var obj = Object.create(TensorF64.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorF64.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensorf64_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Float64Array} values\n    * @returns {TensorF64}\n    */\n    TensorF64.create = function (shape, values) {\n        var ret = wasm.tensorf64_create(addHeapObject(shape), addHeapObject(values));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorF64}\n    */\n    TensorF64.create_constant = function (shape, value) {\n        var ret = wasm.tensorf64_create_constant(addHeapObject(shape), value);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {Float64Array}\n    */\n    TensorF64.prototype.get_vals = function () {\n        var ret = wasm.tensorf64_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorF64.prototype.get_shape = function () {\n        var ret = wasm.tensorf64_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.exp = function () {\n        var ret = wasm.tensorf64_exp(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.log = function () {\n        var ret = wasm.tensorf64_log(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sqrt = function () {\n        var ret = wasm.tensorf64_sqrt(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sin = function () {\n        var ret = wasm.tensorf64_sin(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.cos = function () {\n        var ret = wasm.tensorf64_cos(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.tan = function () {\n        var ret = wasm.tensorf64_tan(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.asin = function () {\n        var ret = wasm.tensorf64_asin(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.acos = function () {\n        var ret = wasm.tensorf64_acos(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.atan = function () {\n        var ret = wasm.tensorf64_atan(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sinh = function () {\n        var ret = wasm.tensorf64_sinh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.cosh = function () {\n        var ret = wasm.tensorf64_cosh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.tanh = function () {\n        var ret = wasm.tensorf64_tanh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.asinh = function () {\n        var ret = wasm.tensorf64_asinh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.acosh = function () {\n        var ret = wasm.tensorf64_acosh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.atanh = function () {\n        var ret = wasm.tensorf64_atanh(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sigmoid = function () {\n        var ret = wasm.tensorf64_sigmoid(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.floor = function () {\n        var ret = wasm.tensorf64_floor(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.ceil = function () {\n        var ret = wasm.tensorf64_ceil(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.round = function () {\n        var ret = wasm.tensorf64_round(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensorf64_power_scalar(this.ptr, power, factor);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.hard_sigmoid = function (alpha, beta) {\n        var ret = wasm.tensorf64_hard_sigmoid(this.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.abs = function () {\n        var ret = wasm.tensorf64_abs(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sign = function () {\n        var ret = wasm.tensorf64_sign(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.negate = function () {\n        var ret = wasm.tensorf64_negate(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensorf64_add_multiply_scalar(this.ptr, factor, add);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip = function (min, max) {\n        var ret = wasm.tensorf64_clip(this.ptr, min, max);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip_min = function (min) {\n        var ret = wasm.tensorf64_clip_min(this.ptr, min);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip_max = function (max) {\n        var ret = wasm.tensorf64_clip_max(this.ptr, max);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.power = function (other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_power(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.bce = function (other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_bce(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.bce_back = function (other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_bce_back(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_multiply(this.ptr, other.ptr, alpha);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_divide(this.ptr, other.ptr, alpha);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.reduce_log_sum = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_log_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.reduce_log_sum_exp = function (axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_log_sum_exp(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF64);\n        var ret = wasm.tensorf64_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} kernel\n    * @param {TensorF64} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF64);\n        _assertClass(bias, TensorF64);\n        var ret = wasm.tensorf64_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorF64);\n        var ret = wasm.tensorf64_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensorf64_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensorf64_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.upsample = function (scales) {\n        var ret = wasm.tensorf64_upsample(this.ptr, addHeapObject(scales));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} mean\n    * @param {TensorF64} variance\n    * @param {number} epsilon\n    * @param {TensorF64} scale\n    * @param {TensorF64} bias\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.normalize = function (mean, variance, epsilon, scale, bias) {\n        _assertClass(mean, TensorF64);\n        _assertClass(variance, TensorF64);\n        _assertClass(scale, TensorF64);\n        _assertClass(bias, TensorF64);\n        var ret = wasm.tensorf64_normalize(this.ptr, mean.ptr, variance.ptr, epsilon, scale.ptr, bias.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.matmul = function (other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_matmul(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorF64} c\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorF64);\n        _assertClass(c, TensorF64);\n        var ret = wasm.tensorf64_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} values\n    * @param {Uint32Array} starts\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorF64);\n        var ret = wasm.tensorf64_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.reshape = function (shape) {\n        var ret = wasm.tensorf64_reshape(this.ptr, addHeapObject(shape));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {TensorF64} other\n    * @param {number} axes\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_concat(this.ptr, other.ptr, axes);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.transpose = function (permutation) {\n        var ret = wasm.tensorf64_transpose(this.ptr, addHeapObject(permutation));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.repeat = function (repeats) {\n        var ret = wasm.tensorf64_repeat(this.ptr, addHeapObject(repeats));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.expand = function (shape) {\n        var ret = wasm.tensorf64_expand(this.ptr, addHeapObject(shape));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.copy = function () {\n        var ret = wasm.tensorf64_copy(this.ptr);\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensorf64_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorF64.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorF64}\n    */\n    TensorF64.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensorf64_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorF64.__wrap(ret);\n    };\n    return TensorF64;\n}());\nexport { TensorF64 };\n/**\n*/\nvar TensorI16 = /** @class */ (function () {\n    function TensorI16() {\n    }\n    TensorI16.__wrap = function (ptr) {\n        var obj = Object.create(TensorI16.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorI16.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensori16_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int16Array} values\n    * @returns {TensorI16}\n    */\n    TensorI16.create = function (shape, values) {\n        var ret = wasm.tensori16_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI16}\n    */\n    TensorI16.create_constant = function (shape, value) {\n        var ret = wasm.tensori16_create_constant(addHeapObject(shape), value);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @returns {Int16Array}\n    */\n    TensorI16.prototype.get_vals = function () {\n        var ret = wasm.tensori16_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorI16.prototype.get_shape = function () {\n        var ret = wasm.tensori16_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensori16_power_scalar(this.ptr, power, factor);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.abs = function () {\n        var ret = wasm.tensori16_abs(this.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.sign = function () {\n        var ret = wasm.tensori16_sign(this.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.negate = function () {\n        var ret = wasm.tensori16_negate(this.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensori16_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip = function (min, max) {\n        var ret = wasm.tensori16_clip(this.ptr, min, max);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip_min = function (min) {\n        var ret = wasm.tensori16_clip_min(this.ptr, min);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip_max = function (max) {\n        var ret = wasm.tensori16_clip_max(this.ptr, max);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.power = function (other) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_power(this.ptr, other.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_multiply(this.ptr, other.ptr, alpha);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_divide(this.ptr, other.ptr, alpha);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensori16_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensori16_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensori16_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensori16_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensori16_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensori16_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensori16_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI16);\n        var ret = wasm.tensori16_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} kernel\n    * @param {TensorI16} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI16);\n        _assertClass(bias, TensorI16);\n        var ret = wasm.tensori16_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI16);\n        var ret = wasm.tensori16_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori16_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensori16_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.upsample = function (scales) {\n        var ret = wasm.tensori16_upsample(this.ptr, addHeapObject(scales));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.matmul = function (other) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_matmul(this.ptr, other.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI16} c\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI16);\n        _assertClass(c, TensorI16);\n        var ret = wasm.tensori16_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorI16);\n        var ret = wasm.tensori16_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.reshape = function (shape) {\n        var ret = wasm.tensori16_reshape(this.ptr, addHeapObject(shape));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {TensorI16} other\n    * @param {number} axes\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_concat(this.ptr, other.ptr, axes);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.transpose = function (permutation) {\n        var ret = wasm.tensori16_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.repeat = function (repeats) {\n        var ret = wasm.tensori16_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.expand = function (shape) {\n        var ret = wasm.tensori16_expand(this.ptr, addHeapObject(shape));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.copy = function () {\n        var ret = wasm.tensori16_copy(this.ptr);\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensori16_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI16}\n    */\n    TensorI16.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensori16_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI16.__wrap(ret);\n    };\n    return TensorI16;\n}());\nexport { TensorI16 };\n/**\n*/\nvar TensorI32 = /** @class */ (function () {\n    function TensorI32() {\n    }\n    TensorI32.__wrap = function (ptr) {\n        var obj = Object.create(TensorI32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorI32.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensori32_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int32Array} values\n    * @returns {TensorI32}\n    */\n    TensorI32.create = function (shape, values) {\n        var ret = wasm.tensori32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI32}\n    */\n    TensorI32.create_constant = function (shape, value) {\n        var ret = wasm.tensori32_create_constant(addHeapObject(shape), value);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @returns {Int32Array}\n    */\n    TensorI32.prototype.get_vals = function () {\n        var ret = wasm.tensori32_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorI32.prototype.get_shape = function () {\n        var ret = wasm.tensori32_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensori32_power_scalar(this.ptr, power, factor);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.abs = function () {\n        var ret = wasm.tensori32_abs(this.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.sign = function () {\n        var ret = wasm.tensori32_sign(this.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.negate = function () {\n        var ret = wasm.tensori32_negate(this.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensori32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip = function (min, max) {\n        var ret = wasm.tensori32_clip(this.ptr, min, max);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip_min = function (min) {\n        var ret = wasm.tensori32_clip_min(this.ptr, min);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip_max = function (max) {\n        var ret = wasm.tensori32_clip_max(this.ptr, max);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.power = function (other) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_power(this.ptr, other.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_multiply(this.ptr, other.ptr, alpha);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_divide(this.ptr, other.ptr, alpha);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensori32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensori32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensori32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensori32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensori32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensori32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensori32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI32);\n        var ret = wasm.tensori32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} kernel\n    * @param {TensorI32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI32);\n        _assertClass(bias, TensorI32);\n        var ret = wasm.tensori32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI32);\n        var ret = wasm.tensori32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensori32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.upsample = function (scales) {\n        var ret = wasm.tensori32_upsample(this.ptr, addHeapObject(scales));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.matmul = function (other) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_matmul(this.ptr, other.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI32} c\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI32);\n        _assertClass(c, TensorI32);\n        var ret = wasm.tensori32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorI32);\n        var ret = wasm.tensori32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.reshape = function (shape) {\n        var ret = wasm.tensori32_reshape(this.ptr, addHeapObject(shape));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {TensorI32} other\n    * @param {number} axes\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_concat(this.ptr, other.ptr, axes);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.transpose = function (permutation) {\n        var ret = wasm.tensori32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.repeat = function (repeats) {\n        var ret = wasm.tensori32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.expand = function (shape) {\n        var ret = wasm.tensori32_expand(this.ptr, addHeapObject(shape));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.copy = function () {\n        var ret = wasm.tensori32_copy(this.ptr);\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensori32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI32}\n    */\n    TensorI32.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensori32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI32.__wrap(ret);\n    };\n    return TensorI32;\n}());\nexport { TensorI32 };\n/**\n*/\nvar TensorI8 = /** @class */ (function () {\n    function TensorI8() {\n    }\n    TensorI8.__wrap = function (ptr) {\n        var obj = Object.create(TensorI8.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorI8.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensori8_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int8Array} values\n    * @returns {TensorI8}\n    */\n    TensorI8.create = function (shape, values) {\n        var ret = wasm.tensori8_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI8}\n    */\n    TensorI8.create_constant = function (shape, value) {\n        var ret = wasm.tensori8_create_constant(addHeapObject(shape), value);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @returns {Int8Array}\n    */\n    TensorI8.prototype.get_vals = function () {\n        var ret = wasm.tensori8_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorI8.prototype.get_shape = function () {\n        var ret = wasm.tensori8_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensori8_power_scalar(this.ptr, power, factor);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.abs = function () {\n        var ret = wasm.tensori8_abs(this.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.sign = function () {\n        var ret = wasm.tensori8_sign(this.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.negate = function () {\n        var ret = wasm.tensori8_negate(this.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensori8_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip = function (min, max) {\n        var ret = wasm.tensori8_clip(this.ptr, min, max);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip_min = function (min) {\n        var ret = wasm.tensori8_clip_min(this.ptr, min);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip_max = function (max) {\n        var ret = wasm.tensori8_clip_max(this.ptr, max);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.power = function (other) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_power(this.ptr, other.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_multiply(this.ptr, other.ptr, alpha);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_divide(this.ptr, other.ptr, alpha);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensori8_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensori8_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensori8_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensori8_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensori8_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensori8_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensori8_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI8);\n        var ret = wasm.tensori8_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} kernel\n    * @param {TensorI8} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI8);\n        _assertClass(bias, TensorI8);\n        var ret = wasm.tensori8_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI8);\n        var ret = wasm.tensori8_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori8_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensori8_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.upsample = function (scales) {\n        var ret = wasm.tensori8_upsample(this.ptr, addHeapObject(scales));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.matmul = function (other) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_matmul(this.ptr, other.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI8} c\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI8);\n        _assertClass(c, TensorI8);\n        var ret = wasm.tensori8_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorI8);\n        var ret = wasm.tensori8_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.reshape = function (shape) {\n        var ret = wasm.tensori8_reshape(this.ptr, addHeapObject(shape));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {TensorI8} other\n    * @param {number} axes\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_concat(this.ptr, other.ptr, axes);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.transpose = function (permutation) {\n        var ret = wasm.tensori8_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.repeat = function (repeats) {\n        var ret = wasm.tensori8_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.expand = function (shape) {\n        var ret = wasm.tensori8_expand(this.ptr, addHeapObject(shape));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.copy = function () {\n        var ret = wasm.tensori8_copy(this.ptr);\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensori8_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI8}\n    */\n    TensorI8.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensori8_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI8.__wrap(ret);\n    };\n    return TensorI8;\n}());\nexport { TensorI8 };\n/**\n*/\nvar TensorU16 = /** @class */ (function () {\n    function TensorU16() {\n    }\n    TensorU16.__wrap = function (ptr) {\n        var obj = Object.create(TensorU16.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorU16.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensoru16_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint16Array} values\n    * @returns {TensorU16}\n    */\n    TensorU16.create = function (shape, values) {\n        var ret = wasm.tensoru16_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU16}\n    */\n    TensorU16.create_constant = function (shape, value) {\n        var ret = wasm.tensoru16_create_constant(addHeapObject(shape), value);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @returns {Uint16Array}\n    */\n    TensorU16.prototype.get_vals = function () {\n        var ret = wasm.tensoru16_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorU16.prototype.get_shape = function () {\n        var ret = wasm.tensoru16_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensoru16_power_scalar(this.ptr, power, factor);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensoru16_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip = function (min, max) {\n        var ret = wasm.tensoru16_clip(this.ptr, min, max);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip_min = function (min) {\n        var ret = wasm.tensoru16_clip_min(this.ptr, min);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip_max = function (max) {\n        var ret = wasm.tensoru16_clip_max(this.ptr, max);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.power = function (other) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_power(this.ptr, other.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_multiply(this.ptr, other.ptr, alpha);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_divide(this.ptr, other.ptr, alpha);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru16_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU16);\n        var ret = wasm.tensoru16_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} kernel\n    * @param {TensorU16} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU16);\n        _assertClass(bias, TensorU16);\n        var ret = wasm.tensoru16_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU16);\n        var ret = wasm.tensoru16_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru16_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensoru16_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.upsample = function (scales) {\n        var ret = wasm.tensoru16_upsample(this.ptr, addHeapObject(scales));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.matmul = function (other) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_matmul(this.ptr, other.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU16} c\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU16);\n        _assertClass(c, TensorU16);\n        var ret = wasm.tensoru16_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorU16);\n        var ret = wasm.tensoru16_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.reshape = function (shape) {\n        var ret = wasm.tensoru16_reshape(this.ptr, addHeapObject(shape));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {TensorU16} other\n    * @param {number} axes\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_concat(this.ptr, other.ptr, axes);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.transpose = function (permutation) {\n        var ret = wasm.tensoru16_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.repeat = function (repeats) {\n        var ret = wasm.tensoru16_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.expand = function (shape) {\n        var ret = wasm.tensoru16_expand(this.ptr, addHeapObject(shape));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.copy = function () {\n        var ret = wasm.tensoru16_copy(this.ptr);\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensoru16_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU16.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU16}\n    */\n    TensorU16.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensoru16_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU16.__wrap(ret);\n    };\n    return TensorU16;\n}());\nexport { TensorU16 };\n/**\n*/\nvar TensorU32 = /** @class */ (function () {\n    function TensorU32() {\n    }\n    TensorU32.__wrap = function (ptr) {\n        var obj = Object.create(TensorU32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorU32.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensoru32_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint32Array} values\n    * @returns {TensorU32}\n    */\n    TensorU32.create = function (shape, values) {\n        var ret = wasm.tensoru32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU32}\n    */\n    TensorU32.create_constant = function (shape, value) {\n        var ret = wasm.tensoru32_create_constant(addHeapObject(shape), value);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorU32.prototype.get_vals = function () {\n        var ret = wasm.tensoru32_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorU32.prototype.get_shape = function () {\n        var ret = wasm.tensoru32_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensoru32_power_scalar(this.ptr, power, factor);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensoru32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip = function (min, max) {\n        var ret = wasm.tensoru32_clip(this.ptr, min, max);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip_min = function (min) {\n        var ret = wasm.tensoru32_clip_min(this.ptr, min);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip_max = function (max) {\n        var ret = wasm.tensoru32_clip_max(this.ptr, max);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.power = function (other) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_power(this.ptr, other.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_multiply(this.ptr, other.ptr, alpha);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_divide(this.ptr, other.ptr, alpha);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU32);\n        var ret = wasm.tensoru32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} kernel\n    * @param {TensorU32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU32);\n        _assertClass(bias, TensorU32);\n        var ret = wasm.tensoru32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU32);\n        var ret = wasm.tensoru32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensoru32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.upsample = function (scales) {\n        var ret = wasm.tensoru32_upsample(this.ptr, addHeapObject(scales));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.matmul = function (other) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_matmul(this.ptr, other.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU32} c\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU32);\n        _assertClass(c, TensorU32);\n        var ret = wasm.tensoru32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorU32);\n        var ret = wasm.tensoru32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.reshape = function (shape) {\n        var ret = wasm.tensoru32_reshape(this.ptr, addHeapObject(shape));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {TensorU32} other\n    * @param {number} axes\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_concat(this.ptr, other.ptr, axes);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.transpose = function (permutation) {\n        var ret = wasm.tensoru32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.repeat = function (repeats) {\n        var ret = wasm.tensoru32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.expand = function (shape) {\n        var ret = wasm.tensoru32_expand(this.ptr, addHeapObject(shape));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.copy = function () {\n        var ret = wasm.tensoru32_copy(this.ptr);\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensoru32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU32.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU32}\n    */\n    TensorU32.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensoru32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU32.__wrap(ret);\n    };\n    return TensorU32;\n}());\nexport { TensorU32 };\n/**\n*/\nvar TensorU8 = /** @class */ (function () {\n    function TensorU8() {\n    }\n    TensorU8.__wrap = function (ptr) {\n        var obj = Object.create(TensorU8.prototype);\n        obj.ptr = ptr;\n        return obj;\n    };\n    TensorU8.prototype.free = function () {\n        var ptr = this.ptr;\n        this.ptr = 0;\n        wasm.__wbg_tensoru8_free(ptr);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint8Array} values\n    * @returns {TensorU8}\n    */\n    TensorU8.create = function (shape, values) {\n        var ret = wasm.tensoru8_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU8}\n    */\n    TensorU8.create_constant = function (shape, value) {\n        var ret = wasm.tensoru8_create_constant(addHeapObject(shape), value);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @returns {Uint8Array}\n    */\n    TensorU8.prototype.get_vals = function () {\n        var ret = wasm.tensoru8_get_vals(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @returns {Uint32Array}\n    */\n    TensorU8.prototype.get_shape = function () {\n        var ret = wasm.tensoru8_get_shape(this.ptr);\n        return takeObject(ret);\n    };\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.power_scalar = function (power, factor) {\n        var ret = wasm.tensoru8_power_scalar(this.ptr, power, factor);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.add_multiply_scalar = function (factor, add) {\n        var ret = wasm.tensoru8_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip = function (min, max) {\n        var ret = wasm.tensoru8_clip(this.ptr, min, max);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip_min = function (min) {\n        var ret = wasm.tensoru8_clip_min(this.ptr, min);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip_max = function (max) {\n        var ret = wasm.tensoru8_clip_max(this.ptr, max);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.power = function (other) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_power(this.ptr, other.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.addition = function (other, alpha, beta) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.subtraction = function (other, alpha, beta) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.multiply = function (other, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_multiply(this.ptr, other.ptr, alpha);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.divide = function (other, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_divide(this.ptr, other.ptr, alpha);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip_backward = function (min, max, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} min\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip_min_backward = function (min, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} max\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.clip_max_backward = function (max, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.sum = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.sum_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.product = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.max = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.min = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.reduce_mean = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.reduce_mean_square = function (axes, keep_dims) {\n        var ret = wasm.tensoru8_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.conv = function (kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU8);\n        var ret = wasm.tensoru8_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} kernel\n    * @param {TensorU8} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.conv_with_bias = function (kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU8);\n        _assertClass(bias, TensorU8);\n        var ret = wasm.tensoru8_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.conv_transpose = function (kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU8);\n        var ret = wasm.tensoru8_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.average_pool = function (kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru8_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.pad = function (pads, mode, value) {\n        var ret = wasm.tensoru8_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.upsample = function (scales) {\n        var ret = wasm.tensoru8_upsample(this.ptr, addHeapObject(scales));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.matmul = function (other) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_matmul(this.ptr, other.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.gemm = function (other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU8} c\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.gemm_with_c = function (other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU8);\n        _assertClass(c, TensorU8);\n        var ret = wasm.tensoru8_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.set_values = function (values, starts) {\n        _assertClass(values, TensorU8);\n        var ret = wasm.tensoru8_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.reshape = function (shape) {\n        var ret = wasm.tensoru8_reshape(this.ptr, addHeapObject(shape));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {TensorU8} other\n    * @param {number} axes\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.concat = function (other, axes) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_concat(this.ptr, other.ptr, axes);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.transpose = function (permutation) {\n        var ret = wasm.tensoru8_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.repeat = function (repeats) {\n        var ret = wasm.tensoru8_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.expand = function (shape) {\n        var ret = wasm.tensoru8_expand(this.ptr, addHeapObject(shape));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.copy = function () {\n        var ret = wasm.tensoru8_copy(this.ptr);\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.gather = function (axis, indices, indice_shape) {\n        var ret = wasm.tensoru8_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU8.__wrap(ret);\n    };\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU8}\n    */\n    TensorU8.prototype.slice = function (starts, ends, axis, steps) {\n        var ret = wasm.tensoru8_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU8.__wrap(ret);\n    };\n    return TensorU8;\n}());\nexport { TensorU8 };\nexport var __wbindgen_object_drop_ref = function (arg0) {\n    takeObject(arg0);\n};\nexport var __wbg_length_c2663a684bd00ed7 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_313b879e6fc45a96 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_fe5c0a81fc6dc5be = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_c645e7c02233b440 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_f2849e182c7f66a6 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_066959e714db878d = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_5451d14971418d5f = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_length_542f394c736acbd8 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport var __wbg_newwithlength_a34fa8d8f6579133 = function (arg0) {\n    var ret = new Int8Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_cbff36a6e9f87747 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_1a62a00188457b0a = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_584c080c6441ab9a = function (arg0) {\n    var ret = new Int16Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_1c5bb84474de0d1e = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_52f5b35b65556557 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_dd3f98ae741324f9 = function (arg0) {\n    var ret = new Int32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_65894fe7a532198d = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_bfc5804eb572c4b6 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_a429e08f8a8fe4b3 = function (arg0) {\n    var ret = new Uint8Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_516fefdaebcecdb1 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_53241afa4f7dbacb = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_0dd44dab0db93194 = function (arg0) {\n    var ret = new Uint16Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_4d375e3926352d65 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_cd5a8389192b2787 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_22e6e266d27d1294 = function (arg0) {\n    var ret = new Uint32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_7de14a8d5bf01cf2 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_60fa756826393086 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2 >>> 0;\n};\nexport var __wbg_newwithlength_b4f5e126ec83388d = function (arg0) {\n    var ret = new Float32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_ac83aab95f5406b3 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_6dc0bfa7a8831af2 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbg_newwithlength_6693d9a0f01cbdbf = function (arg0) {\n    var ret = new Float64Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport var __wbg_getindex_fcee8c3cb65708ea = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport var __wbg_setindex_194f182c70c98091 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport var __wbindgen_throw = function (arg0, arg1) {\n    throw new Error(getStringFromWasm0(arg0, arg1));\n};\n//# sourceMappingURL=rust_wasm_tensor_bg.js.map","module.exports = function(originalModule) {\n\tif (!originalModule.webpackPolyfill) {\n\t\tvar module = Object.create(originalModule);\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"exports\", {\n\t\t\tenumerable: true\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n","export * from \"./rust_wasm_tensor_bg.js\";\n//# sourceMappingURL=rust_wasm_tensor.js.map"],"sourceRoot":""}