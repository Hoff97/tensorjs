{"version":3,"sources":["../../../../lib/wasm/rust_wasm_tensor_bg.js","../node_modules/webpack/buildin/harmony-module.js","../../../../lib/wasm/rust_wasm_tensor.js"],"names":["heap","ret","TensorF32","__wrap","this","ptr","_assertClass","other","TensorF64","TensorI16","axes","keep_dims","addHeapObject","indices","TensorU32","b","TensorI32","TensorI8","TensorU16","TensorU8","getObject","arg0","arg1","module","exports","originalModule","webpackPolyfill","Object","create","children","defineProperty","enumerable","get","l","i"],"mappings":"+hDAEM,EAAO,IAAI,MAAM,IAAI,UAAK,GAIhC,SAAS,EAAU,GAAO,OAAO,EAAK,GAFtC,EAAK,UAAK,EAAW,MAAM,GAAM,GAIjC,IAAI,EAAYA,EAAK,OAQrB,SAAS,EAAW,GAChB,IAAM,EAAM,EAAU,GAEtB,OATJ,SAAoB,GACZ,EAAM,KACV,EAAK,GAAO,EACZ,EAAY,GAKZ,CAAW,GACJ,EAGX,IAEI,EAAoB,IAFoB,qBAAhB,aAA8B,EAAI,EAAO,SAAS,QAAQ,YAAc,aAE3D,QAAS,CAAE,WAAW,EAAM,OAAO,IAE5E,EAAkB,SAElB,IAAI,EAAuB,KAQ3B,SAAS,EAAmB,EAAK,GAC7B,OAAO,EAAkB,QAPI,OAAzB,GAAiC,EAAqB,SAAW,IAAY,SAC7E,EAAuB,IAAI,WAAW,IAAY,SAE/C,GAI2C,SAAS,EAAK,EAAM,IAG1E,SAAS,EAAc,GACf,IAAc,EAAK,QAAQ,EAAK,KAAK,EAAK,OAAS,GACvD,IAAM,EAAM,EAIZ,OAHA,EAAY,EAAK,GAEjB,EAAK,GAAO,EACL,EAGX,SAAS,EAAa,EAAU,GAC5B,KAAM,aAAoB,GACtB,MAAM,IAAI,MAAJ,+BAAkC,EAAM,OAEhD,OAAK,EAAS,IAIpB,IAAa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,IAAwB,KAAK,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,IAAyB,KAAK,QAjDhD,CAAI,IAAJ,MAAI,MAAJ,WAwDQ,IAAI,EAAM,IAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAzDhC,CAAI,IAAJ,MAAI,MAAJ,WA+DQ,IAAI,EAAM,IAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAhEhC,CAAI,IAAJ,OAAI,MAAJ,WAsEQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAvEhC,CAAI,IAAJ,MAAI,MAAJ,WA6EQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KA9EhC,CAAI,IAAJ,MAAI,MAAJ,WAoFQ,IAAI,EAAM,IAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KArFhC,CAAI,IAAJ,MAAI,MAAJ,WA2FQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KA5FhC,CAAI,IAAJ,OAAI,MAAJ,WAkGQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAnGhC,CAAI,IAAJ,OAAI,MAAJ,WAyGQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA1GhC,CAAI,IAAJ,OAAI,MAAJ,WAgHQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAjHhC,CAAI,IAAJ,OAAI,MAAJ,WAuHQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAxHhC,CAAI,IAAJ,OAAI,MAAJ,WA8HQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA/HhC,CAAI,IAAJ,OAAI,MAAJ,WAqIQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,QAAI,MAAJ,WA4IQ,IAAI,EAAM,IAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KA7IhC,CAAI,IAAJ,QAAI,MAAJ,WAmJQ,IAAI,EAAM,IAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KApJhC,CAAI,IAAJ,QAAI,MAAJ,WA0JQ,IAAI,EAAM,IAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KA3JhC,CAAI,IAAJ,UAAI,MAAJ,WAiKQ,IAAI,EAAM,KAAuB,KAAK,KACtC,OAAO,EAAU,OAAO,KAlKhC,CAAI,IAAJ,QAAI,MAAJ,WAwKQ,IAAI,EAAM,IAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KAzKhC,CAAI,IAAJ,OAAI,MAAJ,WA+KQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAhLhC,CAAI,IAAJ,QAAI,MAAJ,WAsLQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KAvLhC,CAAI,IAAJ,eAAI,MAAJ,SA8LiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KAhMhC,CAAI,IAAJ,eAAI,MAAJ,SAuMiB,EAAO,GAChB,IAAI,EAAM,IAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KAzMhC,CAAI,IAAJ,MAAI,MAAJ,WA+MQ,IAAI,EAAM,IAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAhNhC,CAAI,IAAJ,OAAI,MAAJ,WAsNQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAvNhC,CAAI,IAAJ,SAAI,MAAJ,WA6NQ,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,KA9NhC,CAAI,IAAJ,sBAAI,MAAJ,SAqOwB,EAAQ,GACxB,IAAIC,EAAM,IAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAOC,EAAUC,OAAOF,KAvOhC,CAAI,IAAJ,OAAI,MAAJ,SA8OS,EAAK,GACN,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,KAhPhC,CAAI,IAAJ,WAAI,MAAJ,SAsPa,GACL,IAAIA,EAAM,IAAwB,KAAK,IAAK,GAC5C,OAAOC,EAAUC,OAAOF,KAxPhC,CAAI,IAAJ,WAAI,MAAJ,SA8Pa,GACL,IAAI,EAAM,IAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KAhQhC,CAAI,IAAJ,QAAI,MAAJ,SAsQU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,KAzQhC,CAAI,IAAJ,MAAI,MAAJ,SA+QQ,GACA,EAAa,EAAO,GACpB,IAAI,EAAM,IAAmB,KAAK,IAAK,EAAM,KAC7C,OAAO,EAAU,OAAO,KAlRhC,CAAI,IAAJ,WAAI,MAAJ,SAwRa,GACL,EAAa,EAAO,GACpB,IAAI,EAAM,IAAwB,KAAK,IAAK,EAAM,KAClD,OAAO,EAAU,OAAO,KA3RhC,CAAI,IAAJ,WAAI,MAAJ,SAmSa,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,IAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,KAtShC,CAAI,IAAJ,cAAI,MAAJ,SA8SgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KAjThC,CAAI,IAAJ,WAAI,MAAJ,SAwTa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KA3ThC,CAAI,IAAJ,SAAI,MAAJ,SAkUW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KArUhC,CAAI,IAAJ,gBAAI,MAAJ,SA6UkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,IAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,KAhVhC,CAAI,IAAJ,oBAAI,MAAJ,SAuVsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,IAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA1VhC,CAAI,IAAJ,oBAAI,MAAJ,SAiWsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,IAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KApWhC,CAAI,IAAJ,MAAI,MAAJ,SA2WQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KA7WhC,CAAI,IAAJ,aAAI,MAAJ,SAoXe,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,KAtXhC,CAAI,IAAJ,UAAI,MAAJ,SA6XY,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,KA/XhC,CAAI,IAAJ,MAAI,MAAJ,SAsYQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAxYhC,CAAI,IAAJ,MAAI,MAAJ,SA+YQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAjZhC,CAAI,IAAJ,cAAI,MAAJ,SAwZgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KA1ZhC,CAAI,IAAJ,qBAAI,MAAJ,SAiauB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KAnahC,CAAI,IAAJ,iBAAI,MAAJ,SA0amB,EAAM,GACjB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAO,GACvE,OAAO,EAAU,OAAO,KA5ahC,CAAI,IAAJ,qBAAI,MAAJ,SAmbuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KArbhC,CAAI,IAAJ,OAAI,MAAJ,SAgcS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KAnchC,CAAI,IAAJ,iBAAI,MAAJ,SA+cmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,IAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,KAndhC,CAAI,IAAJ,iBAAI,MAAJ,SA6dmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,IAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KAhehC,CAAI,IAAJ,eAAI,MAAJ,SAyeiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,IAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,KA3ehC,CAAI,IAAJ,MAAI,MAAJ,SAmfQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KArfhC,CAAI,IAAJ,WAAI,MAAJ,SA2fa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KA7fhC,CAAI,IAAJ,YAAI,MAAJ,SAugBc,EAAM,EAAU,EAAS,EAAO,GACtC,EAAa,EAAM,GACnB,EAAa,EAAU,GACvB,EAAa,EAAO,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAK,IAAK,EAAS,IAAK,EAAS,EAAM,IAAK,EAAK,KAC9F,OAAO,EAAU,OAAO,KA7gBhC,CAAI,IAAJ,SAAI,MAAJ,SAmhBW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,KAthBhC,CAAI,IAAJ,OAAI,MAAJ,SA+hBS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,IAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KAliBhC,CAAI,IAAJ,cAAI,MAAJ,SA6iBgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,IAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KAjjBhC,CAAI,IAAJ,aAAI,MAAJ,SAwjBe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,KA3jBhC,CAAI,IAAJ,UAAI,MAAJ,SAikBY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KAnkBhC,CAAI,IAAJ,SAAI,MAAJ,SA0kBW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KA7kBhC,CAAI,IAAJ,YAAI,MAAJ,SAmlBc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KArlBhC,CAAI,IAAJ,SAAI,MAAJ,SA2lBW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA7lBhC,CAAI,IAAJ,SAAI,MAAJ,SAmmBW,GACH,IAAIA,EAAM,IAAsBG,KAAKC,IAAK,EAAc,IACxD,OAAOH,EAAUC,OAAOF,KArmBhC,CAAI,IAAJ,OAAI,MAAJ,WA2mBQ,IAAI,EAAM,IAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA5mBhC,CAAI,IAAJ,SAAI,MAAJ,SAonBW,EAAM,EAAS,GAClB,IAAI,EAAM,IAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KAtnBhC,CAAI,IAAJ,QAAI,MAAJ,SA+nBU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KAjoBhC,CAAI,IAAJ,sBAAI,MAAJ,SAyoBwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KA7oBhC,CAAI,IAAJ,mBAAI,MAAJ,SAupBqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,IAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAO,EAAU,OAAO,KA3pBhC,CAAI,IAAJ,wBAAI,MAAJ,SAqqB0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAO,EAAU,OAAO,KAzqBhC,CAAI,IAAJ,wBAAI,MAAJ,SAkrB0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KAtrBhC,CAAI,IAAJ,sBAAI,MAAJ,SA+rBwB,EAAS,EAAG,EAAc,GAC1CK,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,IAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAO,EAAU,OAAO,KAnsBhC,CAAI,IAAJ,oBAAI,MAAJ,SA8sBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjEA,EAAa,EAAS,GACtBA,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,IAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KAntBhC,CAAI,IAAJ,yBAAI,MAAJ,SA8tB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtEA,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAO,EAAU,OAAO,KAnuBhC,CAAI,IAAJ,uBAAI,MAAJ,SA6uByB,EAAS,EAAW,EAAU,EAAc,GAC7DA,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,IAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAO,EAAU,OAAO,KAlvBhC,CAAI,IAAJ,yBAAI,MAAJ,SA4vB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KAjwBhC,CAAI,IAAJ,aAAI,MAAJ,SA0wBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA7wBhC,CAAI,IAAJ,oBAAI,MAAJ,SAsxBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KAzxBhC,CAAI,IAAJ,qBAAI,MAAJ,SAkyBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KAryBhC,CAAI,IAAJ,iBAAI,MAAJ,SA8yBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KAjzBhC,CAAI,IAAJ,aAAI,MAAJ,SA0zBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA7zBhC,CAAI,IAAJ,aAAI,MAAJ,SAs0Be,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAz0BhC,CAAI,IAAJ,6BAAI,MAAJ,SAk1B+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAU,OAAO,KAr1BhC,CAAI,IAAJ,wBAAI,MAAJ,SA81B0B,EAAO,EAAS,EAAM,GACxC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACjH,OAAO,EAAU,OAAO,KAj2BhC,CAAI,IAAJ,4BAAI,MAAJ,SA02B8B,EAAO,EAAS,EAAM,GAC5C,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrH,OAAO,EAAU,OAAO,MA72BhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,IAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,IAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KAk3Ba,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAwB,KAAK,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAyB,KAAK,QAjDhD,CAAI,IAAJ,MAAI,MAAJ,WAwDQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAzDhC,CAAI,IAAJ,MAAI,MAAJ,WA+DQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAhEhC,CAAI,IAAJ,OAAI,MAAJ,WAsEQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAvEhC,CAAI,IAAJ,MAAI,MAAJ,WA6EQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KA9EhC,CAAI,IAAJ,MAAI,MAAJ,WAoFQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KArFhC,CAAI,IAAJ,MAAI,MAAJ,WA2FQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KA5FhC,CAAI,IAAJ,OAAI,MAAJ,WAkGQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAnGhC,CAAI,IAAJ,OAAI,MAAJ,WAyGQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA1GhC,CAAI,IAAJ,OAAI,MAAJ,WAgHQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAjHhC,CAAI,IAAJ,OAAI,MAAJ,WAuHQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAxHhC,CAAI,IAAJ,OAAI,MAAJ,WA8HQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA/HhC,CAAI,IAAJ,OAAI,MAAJ,WAqIQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,QAAI,MAAJ,WA4IQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KA7IhC,CAAI,IAAJ,QAAI,MAAJ,WAmJQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KApJhC,CAAI,IAAJ,QAAI,MAAJ,WA0JQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KA3JhC,CAAI,IAAJ,UAAI,MAAJ,WAiKQ,IAAI,EAAM,KAAuB,KAAK,KACtC,OAAO,EAAU,OAAO,KAlKhC,CAAI,IAAJ,QAAI,MAAJ,WAwKQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KAzKhC,CAAI,IAAJ,OAAI,MAAJ,WA+KQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAhLhC,CAAI,IAAJ,QAAI,MAAJ,WAsLQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAU,OAAO,KAvLhC,CAAI,IAAJ,eAAI,MAAJ,SA8LiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KAhMhC,CAAI,IAAJ,eAAI,MAAJ,SAuMiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KAzMhC,CAAI,IAAJ,MAAI,MAAJ,WA+MQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAhNhC,CAAI,IAAJ,OAAI,MAAJ,WAsNQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAvNhC,CAAI,IAAJ,SAAI,MAAJ,WA6NQ,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,KA9NhC,CAAI,IAAJ,sBAAI,MAAJ,SAqOwB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,KAvOhC,CAAI,IAAJ,OAAI,MAAJ,SA8OS,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,KAhPhC,CAAI,IAAJ,WAAI,MAAJ,SAsPa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KAxPhC,CAAI,IAAJ,WAAI,MAAJ,SA8Pa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KAhQhC,CAAI,IAAJ,QAAI,MAAJ,SAsQU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,KAzQhC,CAAI,IAAJ,MAAI,MAAJ,SA+QQ,GACA,EAAa,EAAO,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,KAC7C,OAAO,EAAU,OAAO,KAlRhC,CAAI,IAAJ,WAAI,MAAJ,SAwRa,GACLA,EAAaC,EAAOC,GACpB,IAAIP,EAAM,KAAwB,KAAK,IAAK,EAAM,KAClD,OAAOO,EAAUL,OAAOF,KA3RhC,CAAI,IAAJ,WAAI,MAAJ,SAmSa,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,KAtShC,CAAI,IAAJ,cAAI,MAAJ,SA8SgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KAjThC,CAAI,IAAJ,WAAI,MAAJ,SAwTa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KA3ThC,CAAI,IAAJ,SAAI,MAAJ,SAkUW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KArUhC,CAAI,IAAJ,gBAAI,MAAJ,SA6UkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,KAhVhC,CAAI,IAAJ,oBAAI,MAAJ,SAuVsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA1VhC,CAAI,IAAJ,oBAAI,MAAJ,SAiWsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KApWhC,CAAI,IAAJ,MAAI,MAAJ,SA2WQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KA7WhC,CAAI,IAAJ,aAAI,MAAJ,SAoXe,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,KAtXhC,CAAI,IAAJ,UAAI,MAAJ,SA6XY,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,KA/XhC,CAAI,IAAJ,MAAI,MAAJ,SAsYQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAxYhC,CAAI,IAAJ,MAAI,MAAJ,SA+YQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAjZhC,CAAI,IAAJ,cAAI,MAAJ,SAwZgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KA1ZhC,CAAI,IAAJ,qBAAI,MAAJ,SAiauB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KAnahC,CAAI,IAAJ,iBAAI,MAAJ,SA0amB,EAAM,GACjB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAO,GACvE,OAAO,EAAU,OAAO,KA5ahC,CAAI,IAAJ,qBAAI,MAAJ,SAmbuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KArbhC,CAAI,IAAJ,OAAI,MAAJ,SAgcS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KAnchC,CAAI,IAAJ,iBAAI,MAAJ,SA+cmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,KAndhC,CAAI,IAAJ,iBAAI,MAAJ,SA6dmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KAhehC,CAAI,IAAJ,eAAI,MAAJ,SAyeiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,KA3ehC,CAAI,IAAJ,MAAI,MAAJ,SAmfQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KArfhC,CAAI,IAAJ,WAAI,MAAJ,SA2fa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KA7fhC,CAAI,IAAJ,YAAI,MAAJ,SAugBc,EAAM,EAAU,EAAS,EAAO,GACtC,EAAa,EAAM,GACnB,EAAa,EAAU,GACvBK,EAAa,EAAOE,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAK,IAAK,EAAS,IAAK,EAAS,EAAM,IAAK,EAAK,KAC9F,OAAO,EAAU,OAAO,KA7gBhC,CAAI,IAAJ,SAAI,MAAJ,SAmhBW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,KAthBhC,CAAI,IAAJ,OAAI,MAAJ,SA+hBS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KAliBhC,CAAI,IAAJ,cAAI,MAAJ,SA6iBgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KAjjBhC,CAAI,IAAJ,aAAI,MAAJ,SAwjBe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,KA3jBhC,CAAI,IAAJ,UAAI,MAAJ,SAikBY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KAnkBhC,CAAI,IAAJ,SAAI,MAAJ,SA0kBW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KA7kBhC,CAAI,IAAJ,YAAI,MAAJ,SAmlBc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KArlBhC,CAAI,IAAJ,SAAI,MAAJ,SA2lBW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA7lBhC,CAAI,IAAJ,SAAI,MAAJ,SAmmBW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KArmBhC,CAAI,IAAJ,OAAI,MAAJ,WA2mBQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA5mBhC,CAAI,IAAJ,SAAI,MAAJ,SAonBW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KAtnBhC,CAAI,IAAJ,QAAI,MAAJ,SA+nBU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KAjoBhC,CAAI,IAAJ,sBAAI,MAAJ,SAyoBwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KA7oBhC,CAAI,IAAJ,mBAAI,MAAJ,SAupBqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAO,EAAU,OAAO,KA3pBhC,CAAI,IAAJ,wBAAI,MAAJ,SAqqB0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAO,EAAU,OAAO,KAzqBhC,CAAI,IAAJ,wBAAI,MAAJ,SAkrB0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KAtrBhC,CAAI,IAAJ,sBAAI,MAAJ,SA+rBwB,EAAS,EAAG,EAAc,GAC1C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAO,EAAU,OAAO,KAnsBhC,CAAI,IAAJ,oBAAI,MAAJ,SA8sBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KAntBhC,CAAI,IAAJ,yBAAI,MAAJ,SA8tB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAO,EAAU,OAAO,KAnuBhC,CAAI,IAAJ,uBAAI,MAAJ,SA6uByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAO,EAAU,OAAO,KAlvBhC,CAAI,IAAJ,yBAAI,MAAJ,SA4vB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KAjwBhC,CAAI,IAAJ,aAAI,MAAJ,SA0wBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA7wBhC,CAAI,IAAJ,oBAAI,MAAJ,SAsxBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KAzxBhC,CAAI,IAAJ,qBAAI,MAAJ,SAkyBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KAryBhC,CAAI,IAAJ,iBAAI,MAAJ,SA8yBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KAjzBhC,CAAI,IAAJ,aAAI,MAAJ,SA0zBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA7zBhC,CAAI,IAAJ,aAAI,MAAJ,SAs0Be,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAz0BhC,CAAI,IAAJ,6BAAI,MAAJ,SAk1B+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAU,OAAO,KAr1BhC,CAAI,IAAJ,wBAAI,MAAJ,SA81B0B,EAAO,EAAS,EAAM,GACxC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACjH,OAAO,EAAU,OAAO,KAj2BhC,CAAI,IAAJ,4BAAI,MAAJ,SA02B8B,EAAO,EAAS,EAAM,GAC5C,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrH,OAAO,EAAU,OAAO,MA72BhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KAk3Ba,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAwB,KAAK,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAyB,KAAK,QAjDhD,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KA3DhC,CAAI,IAAJ,MAAI,MAAJ,WAiEQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAU,OAAO,KAlEhC,CAAI,IAAJ,OAAI,MAAJ,WAwEQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAzEhC,CAAI,IAAJ,SAAI,MAAJ,WA+EQ,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,KAhFhC,CAAI,IAAJ,sBAAI,MAAJ,SAuFwB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,KAzFhC,CAAI,IAAJ,OAAI,MAAJ,SAgGS,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,KAlGhC,CAAI,IAAJ,WAAI,MAAJ,SAwGa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KA1GhC,CAAI,IAAJ,WAAI,MAAJ,SAgHa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KAlHhC,CAAI,IAAJ,QAAI,MAAJ,SAwHU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,KA3HhC,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,cAAI,MAAJ,SA8IgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KAjJhC,CAAI,IAAJ,WAAI,MAAJ,SAwJa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KA3JhC,CAAI,IAAJ,SAAI,MAAJ,SAkKW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KArKhC,CAAI,IAAJ,gBAAI,MAAJ,SA6KkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,KAhLhC,CAAI,IAAJ,oBAAI,MAAJ,SAuLsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA1LhC,CAAI,IAAJ,oBAAI,MAAJ,SAiMsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAIP,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAOQ,EAAUN,OAAOF,KApMhC,CAAI,IAAJ,MAAI,MAAJ,SA2MQS,EAAMC,GACN,IAAIV,EAAM,KAAmBG,KAAKC,IAAKO,EAAcF,GAAOC,GAC5D,OAAOF,EAAUN,OAAOF,KA7MhC,CAAI,IAAJ,aAAI,MAAJ,SAoNe,EAAM,GACb,IAAIA,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAOQ,EAAUN,OAAOF,KAtNhC,CAAI,IAAJ,UAAI,MAAJ,SA6NY,EAAM,GACV,IAAIA,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAOQ,EAAUN,OAAOF,KA/NhC,CAAI,IAAJ,MAAI,MAAJ,SAsOQ,EAAM,GACN,IAAIA,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAOQ,EAAUN,OAAOF,KAxOhC,CAAI,IAAJ,MAAI,MAAJ,SA+OQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAjPhC,CAAI,IAAJ,cAAI,MAAJ,SAwPgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KA1PhC,CAAI,IAAJ,qBAAI,MAAJ,SAiQuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KAnQhC,CAAI,IAAJ,OAAI,MAAJ,SA8QS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KAjRhC,CAAI,IAAJ,iBAAI,MAAJ,SA6RmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,KAjShC,CAAI,IAAJ,iBAAI,MAAJ,SA2SmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KA9ShC,CAAI,IAAJ,eAAI,MAAJ,SAuTiB,EAAc,EAAM,EAAS,GACtC,IAAIA,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAOQ,EAAUN,OAAOF,KAzThC,CAAI,IAAJ,MAAI,MAAJ,SAiUQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KAnUhC,CAAI,IAAJ,WAAI,MAAJ,SAyUa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KA3UhC,CAAI,IAAJ,SAAI,MAAJ,SAiVW,GACHK,EAAa,EAAO,GACpB,IAAIL,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAOQ,EAAUN,OAAOF,KApVhC,CAAI,IAAJ,OAAI,MAAJ,SA6VS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KAhWhC,CAAI,IAAJ,cAAI,MAAJ,SA2WgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KA/WhC,CAAI,IAAJ,aAAI,MAAJ,SAsXe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,KAzXhC,CAAI,IAAJ,UAAI,MAAJ,SA+XY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KAjYhC,CAAI,IAAJ,SAAI,MAAJ,SAwYW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KA3YhC,CAAI,IAAJ,YAAI,MAAJ,SAiZc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KAnZhC,CAAI,IAAJ,SAAI,MAAJ,SAyZW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA3ZhC,CAAI,IAAJ,SAAI,MAAJ,SAiaW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KAnahC,CAAI,IAAJ,OAAI,MAAJ,WAyaQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA1ahC,CAAI,IAAJ,SAAI,MAAJ,SAkbW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KApbhC,CAAI,IAAJ,QAAI,MAAJ,SA6bU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KA/bhC,CAAI,IAAJ,sBAAI,MAAJ,SAucwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtBK,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KA3chC,CAAI,IAAJ,mBAAI,MAAJ,SAqdqB,EAAS,EAAG,EAAc,EAAO,GAC9CA,EAAaO,EAASC,GACtBR,EAAaS,EAAGN,GAChB,IAAIR,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAOQ,EAAUN,OAAOF,KAzdhC,CAAI,IAAJ,wBAAI,MAAJ,SAme0B,EAAS,EAAG,EAAc,EAAO,GACnDK,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAO,EAAU,OAAO,KAvehC,CAAI,IAAJ,wBAAI,MAAJ,SAgf0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtBA,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KApfhC,CAAI,IAAJ,sBAAI,MAAJ,SA6fwB,EAAS,EAAG,EAAc,GAC1C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAO,EAAU,OAAO,KAjgBhC,CAAI,IAAJ,oBAAI,MAAJ,SA4gBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KAjhBhC,CAAI,IAAJ,yBAAI,MAAJ,SA4hB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAO,EAAU,OAAO,KAjiBhC,CAAI,IAAJ,uBAAI,MAAJ,SA2iByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxBA,EAAa,EAAU,GACvB,IAAIL,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAOQ,EAAUN,OAAOF,KAhjBhC,CAAI,IAAJ,yBAAI,MAAJ,SA0jB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KA/jBhC,CAAI,IAAJ,aAAI,MAAJ,SAwkBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA3kBhC,CAAI,IAAJ,oBAAI,MAAJ,SAolBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KAvlBhC,CAAI,IAAJ,qBAAI,MAAJ,SAgmBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KAnmBhC,CAAI,IAAJ,iBAAI,MAAJ,SA4mBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KA/mBhC,CAAI,IAAJ,aAAI,MAAJ,SAwnBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA3nBhC,CAAI,IAAJ,aAAI,MAAJ,SAooBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAvoBhC,CAAI,IAAJ,6BAAI,MAAJ,SAgpB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAIA,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAUE,OAAOF,MAnpBhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KAwpBa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAwB,KAAK,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAyB,KAAK,QAjDhD,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KA3DhC,CAAI,IAAJ,MAAI,MAAJ,WAiEQ,IAAIA,EAAM,KAAmB,KAAK,KAClC,OAAOe,EAAUb,OAAOF,KAlEhC,CAAI,IAAJ,OAAI,MAAJ,WAwEQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KAzEhC,CAAI,IAAJ,SAAI,MAAJ,WA+EQ,IAAI,EAAM,KAAsB,KAAK,KACrC,OAAO,EAAU,OAAO,KAhFhC,CAAI,IAAJ,sBAAI,MAAJ,SAuFwB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,KAzFhC,CAAI,IAAJ,OAAI,MAAJ,SAgGS,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,KAlGhC,CAAI,IAAJ,WAAI,MAAJ,SAwGa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KA1GhC,CAAI,IAAJ,WAAI,MAAJ,SAgHa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KAlHhC,CAAI,IAAJ,QAAI,MAAJ,SAwHU,GACFK,EAAaC,EAAOS,GACpB,IAAIf,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAOe,EAAUb,OAAOF,KA3HhC,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,cAAI,MAAJ,SA8IgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KAjJhC,CAAI,IAAJ,WAAI,MAAJ,SAwJa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KA3JhC,CAAI,IAAJ,SAAI,MAAJ,SAkKW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KArKhC,CAAI,IAAJ,gBAAI,MAAJ,SA6KkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,KAhLhC,CAAI,IAAJ,oBAAI,MAAJ,SAuLsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA1LhC,CAAI,IAAJ,oBAAI,MAAJ,SAiMsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KApMhC,CAAI,IAAJ,MAAI,MAAJ,SA2MQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KA7MhC,CAAI,IAAJ,aAAI,MAAJ,SAoNe,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,KAtNhC,CAAI,IAAJ,UAAI,MAAJ,SA6NY,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,KA/NhC,CAAI,IAAJ,MAAI,MAAJ,SAsOQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAxOhC,CAAI,IAAJ,MAAI,MAAJ,SA+OQ,EAAM,GACN,IAAIA,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAOe,EAAUb,OAAOF,KAjPhC,CAAI,IAAJ,cAAI,MAAJ,SAwPgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KA1PhC,CAAI,IAAJ,qBAAI,MAAJ,SAiQuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KAnQhC,CAAI,IAAJ,OAAI,MAAJ,SA8QS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KAjRhC,CAAI,IAAJ,iBAAI,MAAJ,SA6RmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,KAjShC,CAAI,IAAJ,iBAAI,MAAJ,SA2SmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KA9ShC,CAAI,IAAJ,eAAI,MAAJ,SAuTiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,KAzThC,CAAI,IAAJ,MAAI,MAAJ,SAiUQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KAnUhC,CAAI,IAAJ,WAAI,MAAJ,SAyUa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KA3UhC,CAAI,IAAJ,SAAI,MAAJ,SAiVW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,KApVhC,CAAI,IAAJ,OAAI,MAAJ,SA6VS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KAhWhC,CAAI,IAAJ,cAAI,MAAJ,SA2WgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KA/WhC,CAAI,IAAJ,aAAI,MAAJ,SAsXe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,KAzXhC,CAAI,IAAJ,UAAI,MAAJ,SA+XY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KAjYhC,CAAI,IAAJ,SAAI,MAAJ,SAwYW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KA3YhC,CAAI,IAAJ,YAAI,MAAJ,SAiZc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KAnZhC,CAAI,IAAJ,SAAI,MAAJ,SAyZW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA3ZhC,CAAI,IAAJ,SAAI,MAAJ,SAiaW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KAnahC,CAAI,IAAJ,OAAI,MAAJ,WAyaQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KA1ahC,CAAI,IAAJ,SAAI,MAAJ,SAkbW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KApbhC,CAAI,IAAJ,QAAI,MAAJ,SA6bU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KA/bhC,CAAI,IAAJ,sBAAI,MAAJ,SAucwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KA3chC,CAAI,IAAJ,mBAAI,MAAJ,SAqdqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAO,EAAU,OAAO,KAzdhC,CAAI,IAAJ,wBAAI,MAAJ,SAme0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAO,EAAU,OAAO,KAvehC,CAAI,IAAJ,wBAAI,MAAJ,SAgf0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KApfhC,CAAI,IAAJ,sBAAI,MAAJ,SA6fwB,EAAS,EAAG,EAAc,GAC1CK,EAAa,EAAS,GACtBA,EAAaS,EAAG,GAChB,IAAId,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAOe,EAAUb,OAAOF,KAjgBhC,CAAI,IAAJ,oBAAI,MAAJ,SA4gBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjEK,EAAa,EAAS,GACtBA,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KAjhBhC,CAAI,IAAJ,yBAAI,MAAJ,SA4hB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtEA,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAO,EAAU,OAAO,KAjiBhC,CAAI,IAAJ,uBAAI,MAAJ,SA2iByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAO,EAAU,OAAO,KAhjBhC,CAAI,IAAJ,yBAAI,MAAJ,SA0jB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KA/jBhC,CAAI,IAAJ,aAAI,MAAJ,SAwkBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA3kBhC,CAAI,IAAJ,oBAAI,MAAJ,SAolBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KAvlBhC,CAAI,IAAJ,qBAAI,MAAJ,SAgmBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KAnmBhC,CAAI,IAAJ,iBAAI,MAAJ,SA4mBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KA/mBhC,CAAI,IAAJ,aAAI,MAAJ,SAwnBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA3nBhC,CAAI,IAAJ,aAAI,MAAJ,SAooBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAvoBhC,CAAI,IAAJ,6BAAI,MAAJ,SAgpB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAU,OAAO,MAnpBhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAIL,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAOe,EAAUb,OAAOF,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KAwpBa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAAyB,KAlBjC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAuB,KAAK,QA1C9C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAwB,KAAK,QAjD/C,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAO,GACtD,OAAO,EAAS,OAAO,KA3D/B,CAAI,IAAJ,MAAI,MAAJ,WAiEQ,IAAI,EAAM,KAAkB,KAAK,KACjC,OAAO,EAAS,OAAO,KAlE/B,CAAI,IAAJ,OAAI,MAAJ,WAwEQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,KAzE/B,CAAI,IAAJ,SAAI,MAAJ,WA+EQ,IAAI,EAAM,KAAqB,KAAK,KACpC,OAAO,EAAS,OAAO,KAhF/B,CAAI,IAAJ,sBAAI,MAAJ,SAuFwB,EAAQ,GACxB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,GAC9D,OAAO,EAAS,OAAO,KAzF/B,CAAI,IAAJ,OAAI,MAAJ,SAgGS,EAAK,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAK,GAC5C,OAAO,EAAS,OAAO,KAlG/B,CAAI,IAAJ,WAAI,MAAJ,SAwGa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,KA1G/B,CAAI,IAAJ,WAAI,MAAJ,SAgHa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,KAlH/B,CAAI,IAAJ,QAAI,MAAJ,SAwHU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,KAC9C,OAAO,EAAS,OAAO,KA3H/B,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC7D,OAAO,EAAS,OAAO,KAtI/B,CAAI,IAAJ,cAAI,MAAJ,SA8IgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAO,GAChE,OAAO,EAAS,OAAO,KAjJ/B,CAAI,IAAJ,WAAI,MAAJ,SAwJa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,GACtD,OAAO,EAAS,OAAO,KA3J/B,CAAI,IAAJ,SAAI,MAAJ,SAkKW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,KArK/B,CAAI,IAAJ,gBAAI,MAAJ,SA6KkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAK,EAAK,EAAK,KAC/D,OAAO,EAAS,OAAO,KAhL/B,CAAI,IAAJ,oBAAI,MAAJ,SAuLsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAIA,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAOgB,EAASd,OAAOF,KA1L/B,CAAI,IAAJ,oBAAI,MAAJ,SAiMsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,KApM/B,CAAI,IAAJ,MAAI,MAAJ,SA2MQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KA7M/B,CAAI,IAAJ,aAAI,MAAJ,SAoNe,EAAM,GACb,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAO,GAClE,OAAO,EAAS,OAAO,KAtN/B,CAAI,IAAJ,UAAI,MAAJ,SA6NY,EAAM,GACV,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,GAAO,GAC/D,OAAO,EAAS,OAAO,KA/N/B,CAAI,IAAJ,MAAI,MAAJ,SAsOQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KAxO/B,CAAI,IAAJ,MAAI,MAAJ,SA+OQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KAjP/B,CAAI,IAAJ,cAAI,MAAJ,SAwPgB,EAAM,GACd,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAS,OAAO,KA1P/B,CAAI,IAAJ,qBAAI,MAAJ,SAiQuB,EAAM,GACrB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAO,GAC1E,OAAO,EAAS,OAAO,KAnQ/B,CAAI,IAAJ,OAAI,MAAJ,SA8QS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACjI,OAAO,EAAS,OAAO,KAjR/B,CAAI,IAAJ,iBAAI,MAAJ,SA6RmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACrJ,OAAO,EAAS,OAAO,KAjS/B,CAAI,IAAJ,iBAAI,MAAJ,SA2SmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IACjI,OAAO,EAAS,OAAO,KA9S/B,CAAI,IAAJ,eAAI,MAAJ,SAuTiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GACzH,OAAO,EAAS,OAAO,KAzT/B,CAAI,IAAJ,MAAI,MAAJ,SAiUQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,EAAM,GACjE,OAAO,EAAS,OAAO,KAnU/B,CAAI,IAAJ,WAAI,MAAJ,SAyUa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAS,OAAO,KA3U/B,CAAI,IAAJ,SAAI,MAAJ,SAiVW,GACHK,EAAa,EAAO,GACpB,IAAIL,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAOgB,EAASd,OAAOF,KApV/B,CAAI,IAAJ,OAAI,MAAJ,SA6VS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC5E,OAAO,EAAS,OAAO,KAhW/B,CAAI,IAAJ,cAAI,MAAJ,SA2WgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GACjG,OAAO,EAAS,OAAO,KA/W/B,CAAI,IAAJ,aAAI,MAAJ,SAsXe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAO,IAAK,EAAc,IACvE,OAAO,EAAS,OAAO,KAzX/B,CAAI,IAAJ,UAAI,MAAJ,SA+XY,GACJ,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAS,OAAO,KAjY/B,CAAI,IAAJ,SAAI,MAAJ,SAwYW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,KA3Y/B,CAAI,IAAJ,YAAI,MAAJ,SAiZc,GACN,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAS,OAAO,KAnZ/B,CAAI,IAAJ,SAAI,MAAJ,SAyZW,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,KA3Z/B,CAAI,IAAJ,SAAI,MAAJ,SAiaW,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,KAna/B,CAAI,IAAJ,OAAI,MAAJ,WAyaQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,KA1a/B,CAAI,IAAJ,SAAI,MAAJ,SAkbW,EAAM,EAAS,GAClB,IAAIA,EAAM,KAAqB,KAAK,IAAK,EAAM,EAAc,GAAUW,EAAc,IACrF,OAAOK,EAASd,OAAOF,KApb/B,CAAI,IAAJ,QAAI,MAAJ,SA6bU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACvH,OAAO,EAAS,OAAO,KA/b/B,CAAI,IAAJ,sBAAI,MAAJ,SAucwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC1E,OAAO,EAAS,OAAO,KA3c/B,CAAI,IAAJ,mBAAI,MAAJ,SAqdqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA+B,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC3G,OAAO,EAAS,OAAO,KAzd/B,CAAI,IAAJ,wBAAI,MAAJ,SAme0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAChH,OAAO,EAAS,OAAO,KAve/B,CAAI,IAAJ,wBAAI,MAAJ,SAgf0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACzG,OAAO,EAAS,OAAO,KApf/B,CAAI,IAAJ,sBAAI,MAAJ,SA6fwB,EAAS,EAAG,EAAc,GAC1C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACvG,OAAO,EAAS,OAAO,KAjgB/B,CAAI,IAAJ,oBAAI,MAAJ,SA4gBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GAClI,OAAO,EAAS,OAAO,KAjhB/B,CAAI,IAAJ,yBAAI,MAAJ,SA4hB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACvI,OAAO,EAAS,OAAO,KAjiB/B,CAAI,IAAJ,uBAAI,MAAJ,SA2iByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC9H,OAAO,EAAS,OAAO,KAhjB/B,CAAI,IAAJ,yBAAI,MAAJ,SA0jB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtBK,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAChI,OAAO,EAAS,OAAO,KA/jB/B,CAAI,IAAJ,aAAI,MAAJ,SAwkBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KA3kB/B,CAAI,IAAJ,oBAAI,MAAJ,SAolBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC5G,OAAO,EAAS,OAAO,KAvlB/B,CAAI,IAAJ,qBAAI,MAAJ,SAgmBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAS,OAAO,KAnmB/B,CAAI,IAAJ,iBAAI,MAAJ,SA4mBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACzG,OAAO,EAAS,OAAO,KA/mB/B,CAAI,IAAJ,aAAI,MAAJ,SAwnBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KA3nB/B,CAAI,IAAJ,aAAI,MAAJ,SAooBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KAvoB/B,CAAI,IAAJ,6BAAI,MAAJ,SAgpB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrH,OAAO,EAAS,OAAO,MAnpB/B,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAS,WAGnC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAqB,EAAc,GAAQ,EAAc,IACnE,OAAO,EAAS,OAAO,KA3B/B,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAIL,EAAM,KAA8B,EAAc,GAAQ,GAC9D,OAAOgB,EAASd,OAAOF,OApC/B,KAwpBa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAwBG,KAAKC,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAyB,KAAK,QAjDhD,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KA3DhC,CAAI,IAAJ,sBAAI,MAAJ,SAkEwB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,KApEhC,CAAI,IAAJ,OAAI,MAAJ,SA2ES,EAAK,GACN,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAO,EAAU,OAAO,KA7EhC,CAAI,IAAJ,WAAI,MAAJ,SAmFa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KArFhC,CAAI,IAAJ,WAAI,MAAJ,SA2Fa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KA7FhC,CAAI,IAAJ,QAAI,MAAJ,SAmGU,GACFC,EAAaC,EAAOW,GACpB,IAAIjB,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAOiB,EAAUf,OAAOF,KAtGhC,CAAI,IAAJ,WAAI,MAAJ,SA8Ga,EAAO,EAAO,GACnBK,EAAa,EAAO,GACpB,IAAIL,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAOiB,EAAUf,OAAOF,KAjHhC,CAAI,IAAJ,cAAI,MAAJ,SAyHgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KA5HhC,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,SAAI,MAAJ,SA6IW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KAhJhC,CAAI,IAAJ,gBAAI,MAAJ,SAwJkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAO,EAAU,OAAO,KA3JhC,CAAI,IAAJ,oBAAI,MAAJ,SAkKsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KArKhC,CAAI,IAAJ,oBAAI,MAAJ,SA4KsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA/KhC,CAAI,IAAJ,MAAI,MAAJ,SAsLQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAxLhC,CAAI,IAAJ,aAAI,MAAJ,SA+Le,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,KAjMhC,CAAI,IAAJ,UAAI,MAAJ,SAwMY,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,KA1MhC,CAAI,IAAJ,MAAI,MAAJ,SAiNQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAnNhC,CAAI,IAAJ,MAAI,MAAJ,SA0NQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KA5NhC,CAAI,IAAJ,cAAI,MAAJ,SAmOgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KArOhC,CAAI,IAAJ,qBAAI,MAAJ,SA4OuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KA9OhC,CAAI,IAAJ,OAAI,MAAJ,SAyPS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KA5PhC,CAAI,IAAJ,iBAAI,MAAJ,SAwQmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAIA,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAOiB,EAAUf,OAAOF,KA5QhC,CAAI,IAAJ,iBAAI,MAAJ,SAsRmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KAzRhC,CAAI,IAAJ,eAAI,MAAJ,SAkSiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,KApShC,CAAI,IAAJ,MAAI,MAAJ,SA4SQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KA9ShC,CAAI,IAAJ,WAAI,MAAJ,SAoTa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KAtThC,CAAI,IAAJ,SAAI,MAAJ,SA4TW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,KA/ThC,CAAI,IAAJ,OAAI,MAAJ,SAwUS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KA3UhC,CAAI,IAAJ,cAAI,MAAJ,SAsVgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KA1VhC,CAAI,IAAJ,aAAI,MAAJ,SAiWe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAIA,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAOiB,EAAUf,OAAOF,KApWhC,CAAI,IAAJ,UAAI,MAAJ,SA0WY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KA5WhC,CAAI,IAAJ,SAAI,MAAJ,SAmXW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KAtXhC,CAAI,IAAJ,YAAI,MAAJ,SA4Xc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KA9XhC,CAAI,IAAJ,SAAI,MAAJ,SAoYW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KAtYhC,CAAI,IAAJ,SAAI,MAAJ,SA4YW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA9YhC,CAAI,IAAJ,OAAI,MAAJ,WAoZQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KArZhC,CAAI,IAAJ,SAAI,MAAJ,SA6ZW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KA/ZhC,CAAI,IAAJ,QAAI,MAAJ,SAwaU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KA1ahC,CAAI,IAAJ,sBAAI,MAAJ,SAkbwB,EAAS,EAAG,GAC5BK,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KAtbhC,CAAI,IAAJ,mBAAI,MAAJ,SAgcqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAO,EAAU,OAAO,KApchC,CAAI,IAAJ,wBAAI,MAAJ,SA8c0B,EAAS,EAAG,EAAc,EAAO,GACnDA,EAAa,EAAS,GACtBA,EAAaS,EAAG,GAChB,IAAId,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAOiB,EAAUf,OAAOF,KAldhC,CAAI,IAAJ,wBAAI,MAAJ,SA2d0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KA/dhC,CAAI,IAAJ,sBAAI,MAAJ,SAwewB,EAAS,EAAG,EAAc,GAC1C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAO,EAAU,OAAO,KA5ehC,CAAI,IAAJ,oBAAI,MAAJ,SAufsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KA5fhC,CAAI,IAAJ,yBAAI,MAAJ,SAugB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxBK,EAAa,EAAU,GACvB,IAAIL,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAOiB,EAAUf,OAAOF,KA5gBhC,CAAI,IAAJ,uBAAI,MAAJ,SAshByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAO,EAAU,OAAO,KA3hBhC,CAAI,IAAJ,yBAAI,MAAJ,SAqiB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KA1iBhC,CAAI,IAAJ,aAAI,MAAJ,SAmjBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAtjBhC,CAAI,IAAJ,oBAAI,MAAJ,SA+jBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KAlkBhC,CAAI,IAAJ,qBAAI,MAAJ,SA2kBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KA9kBhC,CAAI,IAAJ,iBAAI,MAAJ,SAulBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KA1lBhC,CAAI,IAAJ,aAAI,MAAJ,SAmmBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAtmBhC,CAAI,IAAJ,aAAI,MAAJ,SA+mBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAlnBhC,CAAI,IAAJ,6BAAI,MAAJ,SA2nB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAU,OAAO,MA9nBhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KAmoBa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAA0B,KAlBlC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAwB,KAAK,QA1C/C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAyB,KAAK,QAjDhD,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAO,GACvD,OAAO,EAAU,OAAO,KA3DhC,CAAI,IAAJ,sBAAI,MAAJ,SAkEwB,EAAQ,GACxB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,GAC/D,OAAO,EAAU,OAAO,KApEhC,CAAI,IAAJ,OAAI,MAAJ,SA2ES,EAAK,GACN,IAAIA,EAAM,KAAoB,KAAK,IAAK,EAAK,GAC7C,OAAOa,EAAUX,OAAOF,KA7EhC,CAAI,IAAJ,WAAI,MAAJ,SAmFa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KArFhC,CAAI,IAAJ,WAAI,MAAJ,SA2Fa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,GAC5C,OAAO,EAAU,OAAO,KA7FhC,CAAI,IAAJ,QAAI,MAAJ,SAmGU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAU,OAAO,KAtGhC,CAAI,IAAJ,WAAI,MAAJ,SA8Ga,EAAO,EAAO,GACnB,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC9D,OAAO,EAAU,OAAO,KAjHhC,CAAI,IAAJ,cAAI,MAAJ,SAyHgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAO,GACjE,OAAO,EAAU,OAAO,KA5HhC,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAM,IAAK,GACvD,OAAO,EAAU,OAAO,KAtIhC,CAAI,IAAJ,SAAI,MAAJ,SA6IW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KAhJhC,CAAI,IAAJ,gBAAI,MAAJ,SAwJkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAIA,EAAM,KAA6B,KAAK,IAAK,EAAK,EAAK,EAAK,KAChE,OAAOa,EAAUX,OAAOF,KA3JhC,CAAI,IAAJ,oBAAI,MAAJ,SAkKsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KArKhC,CAAI,IAAJ,oBAAI,MAAJ,SA4KsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAK,EAAK,KAC/D,OAAO,EAAU,OAAO,KA/KhC,CAAI,IAAJ,MAAI,MAAJ,SAsLQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAxLhC,CAAI,IAAJ,aAAI,MAAJ,SA+Le,EAAM,GACb,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAO,EAAU,OAAO,KAjMhC,CAAI,IAAJ,UAAI,MAAJ,SAwMY,EAAM,GACV,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,GAAO,GAChE,OAAO,EAAU,OAAO,KA1MhC,CAAI,IAAJ,MAAI,MAAJ,SAiNQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KAnNhC,CAAI,IAAJ,MAAI,MAAJ,SA0NQ,EAAM,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,GAC5D,OAAO,EAAU,OAAO,KA5NhC,CAAI,IAAJ,cAAI,MAAJ,SAmOgB,EAAM,GACd,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAO,GACpE,OAAO,EAAU,OAAO,KArOhC,CAAI,IAAJ,qBAAI,MAAJ,SA4OuB,EAAM,GACrB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAO,GAC3E,OAAO,EAAU,OAAO,KA9OhC,CAAI,IAAJ,OAAI,MAAJ,SAyPS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GAClI,OAAO,EAAU,OAAO,KA5PhC,CAAI,IAAJ,iBAAI,MAAJ,SAwQmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1D,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACtJ,OAAO,EAAU,OAAO,KA5QhC,CAAI,IAAJ,iBAAI,MAAJ,SAsRmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IAClI,OAAO,EAAU,OAAO,KAzRhC,CAAI,IAAJ,eAAI,MAAJ,SAkSiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GAC1H,OAAO,EAAU,OAAO,KApShC,CAAI,IAAJ,MAAI,MAAJ,SA4SQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAc,GAAO,EAAM,GAClE,OAAO,EAAU,OAAO,KA9ShC,CAAI,IAAJ,WAAI,MAAJ,SAoTa,GACL,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAU,OAAO,KAtThC,CAAI,IAAJ,SAAI,MAAJ,SA4TW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,KAChD,OAAO,EAAU,OAAO,KA/ThC,CAAI,IAAJ,OAAI,MAAJ,SAwUS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC7E,OAAO,EAAU,OAAO,KA3UhC,CAAI,IAAJ,cAAI,MAAJ,SAsVgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GAClG,OAAO,EAAU,OAAO,KA1VhC,CAAI,IAAJ,aAAI,MAAJ,SAiWe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAO,IAAK,EAAc,IACxE,OAAO,EAAU,OAAO,KApWhC,CAAI,IAAJ,UAAI,MAAJ,SA0WY,GACJ,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAU,OAAO,KA5WhC,CAAI,IAAJ,SAAI,MAAJ,SAmXW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,IAAK,GACrD,OAAO,EAAU,OAAO,KAtXhC,CAAI,IAAJ,YAAI,MAAJ,SA4Xc,GACN,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,IAC3D,OAAO,EAAU,OAAO,KA9XhC,CAAI,IAAJ,SAAI,MAAJ,SAoYW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KAtYhC,CAAI,IAAJ,SAAI,MAAJ,SA4YW,GACH,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAU,OAAO,KA9YhC,CAAI,IAAJ,OAAI,MAAJ,WAoZQ,IAAI,EAAM,KAAoB,KAAK,KACnC,OAAO,EAAU,OAAO,KArZhC,CAAI,IAAJ,SAAI,MAAJ,SA6ZW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACtF,OAAO,EAAU,OAAO,KA/ZhC,CAAI,IAAJ,QAAI,MAAJ,SAwaU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACxH,OAAO,EAAU,OAAO,KA1ahC,CAAI,IAAJ,yBAAI,MAAJ,SAib2B,EAAkB,GACrC,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAc,GAAmB,EAAc,IACzG,OAAO,EAAU,OAAO,KAnbhC,CAAI,IAAJ,YAAI,MAAJ,SA0bc,EAAM,GACZ,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAM,GACnD,OAAO,EAAU,OAAO,KA5bhC,CAAI,IAAJ,wBAAI,MAAJ,SAoc0B,EAAS,EAAO,GAClC,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAc,GAAU,EAAc,GAAQ,GACvG,OAAO,EAAU,OAAO,KAtchC,CAAI,IAAJ,sBAAI,MAAJ,SA8cwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC3E,OAAO,EAAU,OAAO,KAldhC,CAAI,IAAJ,mBAAI,MAAJ,SA4dqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC5G,OAAO,EAAU,OAAO,KAhehC,CAAI,IAAJ,wBAAI,MAAJ,SA0e0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GACjH,OAAO,EAAU,OAAO,KA9ehC,CAAI,IAAJ,wBAAI,MAAJ,SAuf0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GAC1G,OAAO,EAAU,OAAO,KA3fhC,CAAI,IAAJ,sBAAI,MAAJ,SAogBwB,EAAS,EAAG,EAAc,GAC1CK,EAAa,EAAS,GACtBA,EAAaS,EAAG,GAChB,IAAId,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACxG,OAAOa,EAAUX,OAAOF,KAxgBhC,CAAI,IAAJ,oBAAI,MAAJ,SAmhBsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjEK,EAAa,EAAS,GACtBA,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACnI,OAAO,EAAU,OAAO,KAxhBhC,CAAI,IAAJ,yBAAI,MAAJ,SAmiB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACxI,OAAO,EAAU,OAAO,KAxiBhC,CAAI,IAAJ,uBAAI,MAAJ,SAkjByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC/H,OAAO,EAAU,OAAO,KAvjBhC,CAAI,IAAJ,yBAAI,MAAJ,SAikB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAsC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GACjI,OAAO,EAAU,OAAO,KAtkBhC,CAAI,IAAJ,aAAI,MAAJ,SA+kBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAllBhC,CAAI,IAAJ,oBAAI,MAAJ,SA2lBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAU,OAAO,KA9lBhC,CAAI,IAAJ,qBAAI,MAAJ,SAumBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC9G,OAAO,EAAU,OAAO,KA1mBhC,CAAI,IAAJ,iBAAI,MAAJ,SAmnBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA8B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC1G,OAAO,EAAU,OAAO,KAtnBhC,CAAI,IAAJ,aAAI,MAAJ,SA+nBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KAloBhC,CAAI,IAAJ,aAAI,MAAJ,SA2oBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtG,OAAO,EAAU,OAAO,KA9oBhC,CAAI,IAAJ,6BAAI,MAAJ,SAupB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAA0C,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACtH,OAAO,EAAU,OAAO,MA1pBhC,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAU,WAGpC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAsB,EAAc,GAAQ,EAAc,IACpE,OAAO,EAAU,OAAO,KA3BhC,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA+B,EAAc,GAAQ,GAC/D,OAAO,EAAU,OAAO,OApChC,KA+pBa,EAAb,WAAE,SAAF,IAAI,oBAAF,uBAAE,IAAJ,qBAAI,MAAJ,WAUQ,IAAM,EAAM,KAAK,IAGjB,OAFA,KAAK,IAAM,EAEJ,IAbf,CAAI,IAAJ,OAAI,MAAJ,WAiBQ,IAAM,EAAM,KAAK,qBACjB,IAAyB,KAlBjC,CAAI,IAAJ,WAAI,MAAJ,WA2CQ,OAAO,EADG,KAAuB,KAAK,QA1C9C,CAAI,IAAJ,YAAI,MAAJ,WAkDQ,OAAO,EADG,KAAwB,KAAK,QAjD/C,CAAI,IAAJ,eAAI,MAAJ,SAyDiB,EAAO,GAChB,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAO,GACtD,OAAO,EAAS,OAAO,KA3D/B,CAAI,IAAJ,sBAAI,MAAJ,SAkEwB,EAAQ,GACxB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,GAC9D,OAAO,EAAS,OAAO,KApE/B,CAAI,IAAJ,OAAI,MAAJ,SA2ES,EAAK,GACN,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAK,GAC5C,OAAO,EAAS,OAAO,KA7E/B,CAAI,IAAJ,WAAI,MAAJ,SAmFa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,KArF/B,CAAI,IAAJ,WAAI,MAAJ,SA2Fa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,GAC3C,OAAO,EAAS,OAAO,KA7F/B,CAAI,IAAJ,QAAI,MAAJ,SAmGU,GACF,EAAa,EAAO,GACpB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAM,KAC9C,OAAO,EAAS,OAAO,KAtG/B,CAAI,IAAJ,WAAI,MAAJ,SA8Ga,EAAO,EAAO,GACnBA,EAAa,EAAO,GACpB,IAAIL,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,EAAO,GAC7D,OAAOkB,EAAShB,OAAOF,KAjH/B,CAAI,IAAJ,cAAI,MAAJ,SAyHgB,EAAO,EAAO,GACtB,EAAa,EAAO,GACpB,IAAI,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAO,GAChE,OAAO,EAAS,OAAO,KA5H/B,CAAI,IAAJ,WAAI,MAAJ,SAmIa,EAAO,GACZ,EAAa,EAAO,GACpB,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAM,IAAK,GACtD,OAAO,EAAS,OAAO,KAtI/B,CAAI,IAAJ,SAAI,MAAJ,SA6IW,EAAO,GACV,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAO,EAAS,OAAO,KAhJ/B,CAAI,IAAJ,gBAAI,MAAJ,SAwJkB,EAAK,EAAK,GACpB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA4B,KAAK,IAAK,EAAK,EAAK,EAAK,KAC/D,OAAO,EAAS,OAAO,KA3J/B,CAAI,IAAJ,oBAAI,MAAJ,SAkKsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,KArK/B,CAAI,IAAJ,oBAAI,MAAJ,SA4KsB,EAAK,GACnB,EAAa,EAAM,GACnB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAK,EAAK,KAC9D,OAAO,EAAS,OAAO,KA/K/B,CAAI,IAAJ,MAAI,MAAJ,SAsLQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KAxL/B,CAAI,IAAJ,aAAI,MAAJ,SA+Le,EAAM,GACb,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAO,GAClE,OAAO,EAAS,OAAO,KAjM/B,CAAI,IAAJ,UAAI,MAAJ,SAwMY,EAAM,GACV,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,GAAO,GAC/D,OAAO,EAAS,OAAO,KA1M/B,CAAI,IAAJ,MAAI,MAAJ,SAiNQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KAnN/B,CAAI,IAAJ,MAAI,MAAJ,SA0NQ,EAAM,GACN,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,GAC3D,OAAO,EAAS,OAAO,KA5N/B,CAAI,IAAJ,cAAI,MAAJ,SAmOgB,EAAM,GACd,IAAIA,EAAM,KAA0B,KAAK,IAAK,EAAc,GAAO,GACnE,OAAOkB,EAAShB,OAAOF,KArO/B,CAAI,IAAJ,qBAAI,MAAJ,SA4OuB,EAAM,GACrB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAO,GAC1E,OAAO,EAAS,OAAO,KA9O/B,CAAI,IAAJ,OAAI,MAAJ,SAyPS,EAAQ,EAAW,EAAO,EAAM,EAAS,GAC1C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACjI,OAAO,EAAS,OAAO,KA5P/B,CAAI,IAAJ,iBAAI,MAAJ,SAwQmB,EAAQ,EAAM,EAAW,EAAO,EAAM,EAAS,GAC1DK,EAAa,EAAQ,GACrB,EAAa,EAAM,GACnB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAK,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,GAAU,GACrJ,OAAO,EAAS,OAAO,KA5Q/B,CAAI,IAAJ,iBAAI,MAAJ,SAsRmB,EAAQ,EAAW,EAAO,EAAM,GAC3C,EAAa,EAAQ,GACrB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAO,IAAK,EAAc,GAAY,EAAO,EAAc,GAAO,EAAc,IACjI,OAAO,EAAS,OAAO,KAzR/B,CAAI,IAAJ,eAAI,MAAJ,SAkSiB,EAAc,EAAM,EAAS,GACtC,IAAI,EAAM,KAA2B,KAAK,IAAK,EAAc,GAAe,EAAc,GAAO,EAAc,GAAU,GACzH,OAAO,EAAS,OAAO,KApS/B,CAAI,IAAJ,MAAI,MAAJ,SA4SQ,EAAM,EAAM,GACZ,IAAI,EAAM,KAAkB,KAAK,IAAK,EAAc,GAAO,EAAM,GACjE,OAAO,EAAS,OAAO,KA9S/B,CAAI,IAAJ,WAAI,MAAJ,SAoTa,GACL,IAAI,EAAM,KAAuB,KAAK,IAAK,EAAc,IACzD,OAAO,EAAS,OAAO,KAtT/B,CAAI,IAAJ,SAAI,MAAJ,SA4TW,GACH,EAAa,EAAO,GACpB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,KAC/C,OAAO,EAAS,OAAO,KA/T/B,CAAI,IAAJ,OAAI,MAAJ,SAwUS,EAAO,EAAa,EAAa,GAClC,EAAa,EAAO,GACpB,IAAI,EAAM,KAAmB,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,GAC5E,OAAO,EAAS,OAAO,KA3U/B,CAAI,IAAJ,cAAI,MAAJ,SAsVgB,EAAO,EAAa,EAAa,EAAO,EAAG,GACnD,EAAa,EAAO,GACpB,EAAa,EAAG,GAChB,IAAIL,EAAM,KAA0B,KAAK,IAAK,EAAM,IAAK,EAAa,EAAa,EAAO,EAAE,IAAK,GACjG,OAAOkB,EAAShB,OAAOF,KA1V/B,CAAI,IAAJ,aAAI,MAAJ,SAiWe,EAAQ,GACf,EAAa,EAAQ,GACrB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAO,IAAK,EAAc,IACvE,OAAO,EAAS,OAAO,KApW/B,CAAI,IAAJ,UAAI,MAAJ,SA0WY,GACJ,IAAI,EAAM,KAAsB,KAAK,IAAK,EAAc,IACxD,OAAO,EAAS,OAAO,KA5W/B,CAAI,IAAJ,SAAI,MAAJ,SAmXW,EAAO,GACV,EAAa,EAAO,GACpB,IAAIA,EAAM,KAAqB,KAAK,IAAK,EAAM,IAAK,GACpD,OAAOkB,EAAShB,OAAOF,KAtX/B,CAAI,IAAJ,YAAI,MAAJ,SA4Xc,GACN,IAAI,EAAM,KAAwB,KAAK,IAAK,EAAc,IAC1D,OAAO,EAAS,OAAO,KA9X/B,CAAI,IAAJ,SAAI,MAAJ,SAoYW,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,KAtY/B,CAAI,IAAJ,SAAI,MAAJ,SA4YW,GACH,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAc,IACvD,OAAO,EAAS,OAAO,KA9Y/B,CAAI,IAAJ,OAAI,MAAJ,WAoZQ,IAAI,EAAM,KAAmB,KAAK,KAClC,OAAO,EAAS,OAAO,KArZ/B,CAAI,IAAJ,SAAI,MAAJ,SA6ZW,EAAM,EAAS,GAClB,IAAI,EAAM,KAAqB,KAAK,IAAK,EAAM,EAAc,GAAU,EAAc,IACrF,OAAO,EAAS,OAAO,KA/Z/B,CAAI,IAAJ,QAAI,MAAJ,SAwaU,EAAQ,EAAM,EAAM,GACtB,IAAI,EAAM,KAAoB,KAAK,IAAK,EAAc,GAAS,EAAc,GAAO,EAAc,GAAO,EAAc,IACvH,OAAO,EAAS,OAAO,KA1a/B,CAAI,IAAJ,sBAAI,MAAJ,SAkbwB,EAAS,EAAG,GAC5B,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,GAC1E,OAAO,EAAS,OAAO,KAtb/B,CAAI,IAAJ,mBAAI,MAAJ,SAgcqB,EAAS,EAAG,EAAc,EAAO,GAC9C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAA+B,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAC3G,OAAO,EAAS,OAAO,KApc/B,CAAI,IAAJ,wBAAI,MAAJ,SA8c0B,EAAS,EAAG,EAAc,EAAO,GACnD,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,EAAO,GAChH,OAAO,EAAS,OAAO,KAld/B,CAAI,IAAJ,wBAAI,MAAJ,SA2d0B,EAAS,EAAG,EAAc,GAC5C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAoC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACzG,OAAO,EAAS,OAAO,KA/d/B,CAAI,IAAJ,sBAAI,MAAJ,SAwewB,EAAS,EAAG,EAAc,GAC1C,EAAa,EAAS,GACtB,EAAa,EAAG,GAChB,IAAI,EAAM,KAAkC,KAAK,IAAK,EAAQ,IAAK,EAAE,IAAK,EAAc,GAAe,GACvG,OAAO,EAAS,OAAO,KA5e/B,CAAI,IAAJ,oBAAI,MAAJ,SAufsB,EAAS,EAAW,EAAU,EAAc,EAAO,GACjE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GAClI,OAAO,EAAS,OAAO,KA5f/B,CAAI,IAAJ,yBAAI,MAAJ,SAugB2B,EAAS,EAAW,EAAU,EAAc,EAAO,GACtE,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,EAAO,GACvI,OAAO,EAAS,OAAO,KA5gB/B,CAAI,IAAJ,uBAAI,MAAJ,SAshByB,EAAS,EAAW,EAAU,EAAc,GAC7D,EAAa,EAAS,GACtBK,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAmC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAC9H,OAAO,EAAS,OAAO,KA3hB/B,CAAI,IAAJ,yBAAI,MAAJ,SAqiB2B,EAAS,EAAW,EAAU,EAAc,GAC/D,EAAa,EAAS,GACtB,EAAa,EAAW,GACxB,EAAa,EAAU,GACvB,IAAI,EAAM,KAAqC,KAAK,IAAK,EAAQ,IAAK,EAAU,IAAK,EAAS,IAAK,EAAc,GAAe,GAChI,OAAO,EAAS,OAAO,KA1iB/B,CAAI,IAAJ,aAAI,MAAJ,SAmjBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KAtjB/B,CAAI,IAAJ,oBAAI,MAAJ,SA+jBsB,EAAO,EAAS,EAAM,GACpC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAgC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC5G,OAAO,EAAS,OAAO,KAlkB/B,CAAI,IAAJ,qBAAI,MAAJ,SA2kBuB,EAAO,EAAS,EAAM,GACrC,EAAa,EAAS,GACtB,IAAI,EAAM,KAAiC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GAC7G,OAAO,EAAS,OAAO,KA9kB/B,CAAI,IAAJ,iBAAI,MAAJ,SAulBmB,EAAO,EAAS,EAAM,GACjC,EAAa,EAAS,GACtB,IAAI,EAAM,KAA6B,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACzG,OAAO,EAAS,OAAO,KA1lB/B,CAAI,IAAJ,aAAI,MAAJ,SAmmBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KAtmB/B,CAAI,IAAJ,aAAI,MAAJ,SA+mBe,EAAO,EAAS,EAAM,GAC7B,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyB,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrG,OAAO,EAAS,OAAO,KAlnB/B,CAAI,IAAJ,6BAAI,MAAJ,SA2nB+B,EAAO,EAAS,EAAM,GAC7C,EAAa,EAAS,GACtB,IAAI,EAAM,KAAyC,KAAK,IAAK,EAAc,GAAQ,EAAQ,IAAK,EAAc,GAAO,GACrH,OAAO,EAAS,OAAO,MA9nB/B,EAAI,IAAJ,SAAI,MAAJ,SAEkB,GACV,IAAM,EAAM,OAAO,OAAO,EAAS,WAGnC,OAFA,EAAI,IAAM,EAEH,IANf,CAAI,IAAJ,SAAI,MAAJ,SAyBkB,EAAO,GACjB,IAAI,EAAM,KAAqB,EAAc,GAAQ,EAAc,IACnE,OAAO,EAAS,OAAO,KA3B/B,CAAI,IAAJ,kBAAI,MAAJ,SAkC2B,EAAO,GAC1B,IAAI,EAAM,KAA8B,EAAc,GAAQ,GAC9D,OAAO,EAAS,OAAO,OApC/B,KAkoBa,EAA6B,SAAS,GAC/C,EAAW,IAGF,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADUc,EAAUC,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAgC,SAAS,GAElD,OADU,EAAU,GAAM,QAIjB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,UAAU,IAAS,KAIxB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADUD,EAAUC,GAAMC,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,WAAW,IAAS,KAIzB,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,YAAY,IAAS,KAI1B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,YAAY,IAAS,KAI1B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,IAAS,GAG9B,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,aAAa,IAAS,KAI3B,EAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,EAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,EAAuC,SAAS,GAEzD,OAAO,EADG,IAAI,aAAa,IAAS,KAI3B,GAAkC,SAAS,EAAM,GAE1D,OADU,EAAU,GAAM,IAAS,IAI1B,GAAkC,SAAS,EAAM,EAAM,GAChE,EAAU,GAAM,IAAS,GAAK,GAGrB,GAAmB,SAAS,EAAM,GAC3C,MAAM,IAAI,MAAM,EAAmB,EAAM,O,wCCtyL7CC,EAAOC,QAAU,SAASC,GACzB,IAAKA,EAAeC,gBAAiB,CACpC,IAAIH,EAASI,OAAOC,OAAOH,GAEtBF,EAAOM,WAAUN,EAAOM,SAAW,IACxCF,OAAOG,eAAeP,EAAQ,SAAU,CACvCQ,YAAY,EACZC,IAAK,WACJ,OAAOT,EAAOU,KAGhBN,OAAOG,eAAeP,EAAQ,KAAM,CACnCQ,YAAY,EACZC,IAAK,WACJ,OAAOT,EAAOW,KAGhBP,OAAOG,eAAeP,EAAQ,UAAW,CACxCQ,YAAY,IAEbR,EAAOG,gBAAkB,EAE1B,OAAOH,I,4GCrBR","file":"static/js/3.965ac8ff.chunk.js","sourcesContent":["import * as wasm from './rust_wasm_tensor_bg.wasm';\nconst heap = new Array(32).fill(undefined);\nheap.push(undefined, null, true, false);\nfunction getObject(idx) { return heap[idx]; }\nlet heap_next = heap.length;\nfunction dropObject(idx) {\n    if (idx < 36)\n        return;\n    heap[idx] = heap_next;\n    heap_next = idx;\n}\nfunction takeObject(idx) {\n    const ret = getObject(idx);\n    dropObject(idx);\n    return ret;\n}\nconst lTextDecoder = typeof TextDecoder === 'undefined' ? (0, module.require)('util').TextDecoder : TextDecoder;\nlet cachedTextDecoder = new lTextDecoder('utf-8', { ignoreBOM: true, fatal: true });\ncachedTextDecoder.decode();\nlet cachegetUint8Memory0 = null;\nfunction getUint8Memory0() {\n    if (cachegetUint8Memory0 === null || cachegetUint8Memory0.buffer !== wasm.memory.buffer) {\n        cachegetUint8Memory0 = new Uint8Array(wasm.memory.buffer);\n    }\n    return cachegetUint8Memory0;\n}\nfunction getStringFromWasm0(ptr, len) {\n    return cachedTextDecoder.decode(getUint8Memory0().subarray(ptr, ptr + len));\n}\nfunction addHeapObject(obj) {\n    if (heap_next === heap.length)\n        heap.push(heap.length + 1);\n    const idx = heap_next;\n    heap_next = heap[idx];\n    heap[idx] = obj;\n    return idx;\n}\nfunction _assertClass(instance, klass) {\n    if (!(instance instanceof klass)) {\n        throw new Error(`expected instance of ${klass.name}`);\n    }\n    return instance.ptr;\n}\n/**\n*/\nexport class TensorF32 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorF32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensorf32_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Float32Array} values\n    * @returns {TensorF32}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensorf32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorF32}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensorf32_create_constant(addHeapObject(shape), value);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {Float32Array}\n    */\n    get_vals() {\n        var ret = wasm.tensorf32_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensorf32_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    exp() {\n        var ret = wasm.tensorf32_exp(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    log() {\n        var ret = wasm.tensorf32_log(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    sqrt() {\n        var ret = wasm.tensorf32_sqrt(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    sin() {\n        var ret = wasm.tensorf32_sin(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    cos() {\n        var ret = wasm.tensorf32_cos(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    tan() {\n        var ret = wasm.tensorf32_tan(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    asin() {\n        var ret = wasm.tensorf32_asin(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    acos() {\n        var ret = wasm.tensorf32_acos(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    atan() {\n        var ret = wasm.tensorf32_atan(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    sinh() {\n        var ret = wasm.tensorf32_sinh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    cosh() {\n        var ret = wasm.tensorf32_cosh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    tanh() {\n        var ret = wasm.tensorf32_tanh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    asinh() {\n        var ret = wasm.tensorf32_asinh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    acosh() {\n        var ret = wasm.tensorf32_acosh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    atanh() {\n        var ret = wasm.tensorf32_atanh(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    sigmoid() {\n        var ret = wasm.tensorf32_sigmoid(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    floor() {\n        var ret = wasm.tensorf32_floor(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    ceil() {\n        var ret = wasm.tensorf32_ceil(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    round() {\n        var ret = wasm.tensorf32_round(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorF32}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensorf32_power_scalar(this.ptr, power, factor);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    hard_sigmoid(alpha, beta) {\n        var ret = wasm.tensorf32_hard_sigmoid(this.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    abs() {\n        var ret = wasm.tensorf32_abs(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    sign() {\n        var ret = wasm.tensorf32_sign(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    negate() {\n        var ret = wasm.tensorf32_negate(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorF32}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensorf32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorF32}\n    */\n    clip(min, max) {\n        var ret = wasm.tensorf32_clip(this.ptr, min, max);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorF32}\n    */\n    clip_min(min) {\n        var ret = wasm.tensorf32_clip_min(this.ptr, min);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorF32}\n    */\n    clip_max(max) {\n        var ret = wasm.tensorf32_clip_max(this.ptr, max);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    power(other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_power(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    bce(other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_bce(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    bce_back(other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_bce_back(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_multiply(this.ptr, other.ptr, alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_divide(this.ptr, other.ptr, alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorF32} grad\n    * @returns {TensorF32}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorF32);\n        var ret = wasm.tensorf32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensorf32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensorf32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensorf32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensorf32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensorf32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_log_sum(axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_log_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_log_sum_exp(axes, keep_dims) {\n        var ret = wasm.tensorf32_reduce_log_sum_exp(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF32}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF32);\n        var ret = wasm.tensorf32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} kernel\n    * @param {TensorF32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF32}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF32);\n        _assertClass(bias, TensorF32);\n        var ret = wasm.tensorf32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorF32}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorF32);\n        var ret = wasm.tensorf32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorF32}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensorf32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorF32}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensorf32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorF32}\n    */\n    upsample(scales) {\n        var ret = wasm.tensorf32_upsample(this.ptr, addHeapObject(scales));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} mean\n    * @param {TensorF32} variance\n    * @param {number} epsilon\n    * @param {TensorF32} scale\n    * @param {TensorF32} bias\n    * @returns {TensorF32}\n    */\n    normalize(mean, variance, epsilon, scale, bias) {\n        _assertClass(mean, TensorF32);\n        _assertClass(variance, TensorF32);\n        _assertClass(scale, TensorF32);\n        _assertClass(bias, TensorF32);\n        var ret = wasm.tensorf32_normalize(this.ptr, mean.ptr, variance.ptr, epsilon, scale.ptr, bias.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @returns {TensorF32}\n    */\n    matmul(other) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_matmul(this.ptr, other.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorF32} c\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorF32);\n        _assertClass(c, TensorF32);\n        var ret = wasm.tensorf32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorF32}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorF32);\n        var ret = wasm.tensorf32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF32}\n    */\n    reshape(shape) {\n        var ret = wasm.tensorf32_reshape(this.ptr, addHeapObject(shape));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorF32} other\n    * @param {number} axes\n    * @returns {TensorF32}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorF32);\n        var ret = wasm.tensorf32_concat(this.ptr, other.ptr, axes);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorF32}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensorf32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorF32}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensorf32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF32}\n    */\n    expand(shape) {\n        var ret = wasm.tensorf32_expand(this.ptr, addHeapObject(shape));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF32}\n    */\n    copy() {\n        var ret = wasm.tensorf32_copy(this.ptr);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorF32}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensorf32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorF32}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensorf32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF32} b\n    * @param {number} m\n    * @returns {TensorF32}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF32);\n        var ret = wasm.tensorf32_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF32);\n        var ret = wasm.tensorf32_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF32);\n        var ret = wasm.tensorf32_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF32);\n        var ret = wasm.tensorf32_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF32);\n        var ret = wasm.tensorf32_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF32);\n        var ret = wasm.tensorf32_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF32}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF32);\n        var ret = wasm.tensorf32_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF32);\n        var ret = wasm.tensorf32_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF32}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF32);\n        var ret = wasm.tensorf32_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_log_sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_reduce_log_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF32}\n    */\n    reduce_log_sum_exp_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf32_reduce_log_sum_exp_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF32.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorF64 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorF64.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensorf64_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Float64Array} values\n    * @returns {TensorF64}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensorf64_create(addHeapObject(shape), addHeapObject(values));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorF64}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensorf64_create_constant(addHeapObject(shape), value);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {Float64Array}\n    */\n    get_vals() {\n        var ret = wasm.tensorf64_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensorf64_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    exp() {\n        var ret = wasm.tensorf64_exp(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    log() {\n        var ret = wasm.tensorf64_log(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    sqrt() {\n        var ret = wasm.tensorf64_sqrt(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    sin() {\n        var ret = wasm.tensorf64_sin(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    cos() {\n        var ret = wasm.tensorf64_cos(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    tan() {\n        var ret = wasm.tensorf64_tan(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    asin() {\n        var ret = wasm.tensorf64_asin(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    acos() {\n        var ret = wasm.tensorf64_acos(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    atan() {\n        var ret = wasm.tensorf64_atan(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    sinh() {\n        var ret = wasm.tensorf64_sinh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    cosh() {\n        var ret = wasm.tensorf64_cosh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    tanh() {\n        var ret = wasm.tensorf64_tanh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    asinh() {\n        var ret = wasm.tensorf64_asinh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    acosh() {\n        var ret = wasm.tensorf64_acosh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    atanh() {\n        var ret = wasm.tensorf64_atanh(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    sigmoid() {\n        var ret = wasm.tensorf64_sigmoid(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    floor() {\n        var ret = wasm.tensorf64_floor(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    ceil() {\n        var ret = wasm.tensorf64_ceil(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    round() {\n        var ret = wasm.tensorf64_round(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorF64}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensorf64_power_scalar(this.ptr, power, factor);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    hard_sigmoid(alpha, beta) {\n        var ret = wasm.tensorf64_hard_sigmoid(this.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    abs() {\n        var ret = wasm.tensorf64_abs(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    sign() {\n        var ret = wasm.tensorf64_sign(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    negate() {\n        var ret = wasm.tensorf64_negate(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorF64}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensorf64_add_multiply_scalar(this.ptr, factor, add);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorF64}\n    */\n    clip(min, max) {\n        var ret = wasm.tensorf64_clip(this.ptr, min, max);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorF64}\n    */\n    clip_min(min) {\n        var ret = wasm.tensorf64_clip_min(this.ptr, min);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorF64}\n    */\n    clip_max(max) {\n        var ret = wasm.tensorf64_clip_max(this.ptr, max);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    power(other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_power(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    bce(other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_bce(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    bce_back(other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_bce_back(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_multiply(this.ptr, other.ptr, alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_divide(this.ptr, other.ptr, alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorF64} grad\n    * @returns {TensorF64}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorF64);\n        var ret = wasm.tensorf64_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensorf64_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensorf64_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensorf64_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensorf64_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensorf64_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_log_sum(axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_log_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_log_sum_exp(axes, keep_dims) {\n        var ret = wasm.tensorf64_reduce_log_sum_exp(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF64}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF64);\n        var ret = wasm.tensorf64_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} kernel\n    * @param {TensorF64} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorF64}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorF64);\n        _assertClass(bias, TensorF64);\n        var ret = wasm.tensorf64_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorF64}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorF64);\n        var ret = wasm.tensorf64_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorF64}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensorf64_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorF64}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensorf64_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorF64}\n    */\n    upsample(scales) {\n        var ret = wasm.tensorf64_upsample(this.ptr, addHeapObject(scales));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} mean\n    * @param {TensorF64} variance\n    * @param {number} epsilon\n    * @param {TensorF64} scale\n    * @param {TensorF64} bias\n    * @returns {TensorF64}\n    */\n    normalize(mean, variance, epsilon, scale, bias) {\n        _assertClass(mean, TensorF64);\n        _assertClass(variance, TensorF64);\n        _assertClass(scale, TensorF64);\n        _assertClass(bias, TensorF64);\n        var ret = wasm.tensorf64_normalize(this.ptr, mean.ptr, variance.ptr, epsilon, scale.ptr, bias.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @returns {TensorF64}\n    */\n    matmul(other) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_matmul(this.ptr, other.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorF64} c\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorF64);\n        _assertClass(c, TensorF64);\n        var ret = wasm.tensorf64_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} values\n    * @param {Uint32Array} starts\n    * @returns {TensorF64}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorF64);\n        var ret = wasm.tensorf64_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF64}\n    */\n    reshape(shape) {\n        var ret = wasm.tensorf64_reshape(this.ptr, addHeapObject(shape));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorF64} other\n    * @param {number} axes\n    * @returns {TensorF64}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorF64);\n        var ret = wasm.tensorf64_concat(this.ptr, other.ptr, axes);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorF64}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensorf64_transpose(this.ptr, addHeapObject(permutation));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorF64}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensorf64_repeat(this.ptr, addHeapObject(repeats));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorF64}\n    */\n    expand(shape) {\n        var ret = wasm.tensorf64_expand(this.ptr, addHeapObject(shape));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @returns {TensorF64}\n    */\n    copy() {\n        var ret = wasm.tensorf64_copy(this.ptr);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorF64}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensorf64_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorF64}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensorf64_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF64} b\n    * @param {number} m\n    * @returns {TensorF64}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF64);\n        var ret = wasm.tensorf64_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF64} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF64);\n        var ret = wasm.tensorf64_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF64} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF64);\n        var ret = wasm.tensorf64_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF64} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF64);\n        var ret = wasm.tensorf64_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorF64} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorF64);\n        var ret = wasm.tensorf64_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF64} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF64);\n        var ret = wasm.tensorf64_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF64} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorF64}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF64);\n        var ret = wasm.tensorf64_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF64} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF64);\n        var ret = wasm.tensorf64_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorF64} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorF64}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorF64);\n        var ret = wasm.tensorf64_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_log_sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_reduce_log_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorF64}\n    */\n    reduce_log_sum_exp_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensorf64_reduce_log_sum_exp_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorF64.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorI16 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorI16.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensori16_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int16Array} values\n    * @returns {TensorI16}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensori16_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI16}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensori16_create_constant(addHeapObject(shape), value);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @returns {Int16Array}\n    */\n    get_vals() {\n        var ret = wasm.tensori16_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensori16_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI16}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensori16_power_scalar(this.ptr, power, factor);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI16}\n    */\n    abs() {\n        var ret = wasm.tensori16_abs(this.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI16}\n    */\n    sign() {\n        var ret = wasm.tensori16_sign(this.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI16}\n    */\n    negate() {\n        var ret = wasm.tensori16_negate(this.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI16}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensori16_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI16}\n    */\n    clip(min, max) {\n        var ret = wasm.tensori16_clip(this.ptr, min, max);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorI16}\n    */\n    clip_min(min) {\n        var ret = wasm.tensori16_clip_min(this.ptr, min);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorI16}\n    */\n    clip_max(max) {\n        var ret = wasm.tensori16_clip_max(this.ptr, max);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @returns {TensorI16}\n    */\n    power(other) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_power(this.ptr, other.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_multiply(this.ptr, other.ptr, alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_divide(this.ptr, other.ptr, alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorI16} grad\n    * @returns {TensorI16}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorI16);\n        var ret = wasm.tensori16_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensori16_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensori16_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensori16_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensori16_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensori16_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensori16_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensori16_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI16}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI16);\n        var ret = wasm.tensori16_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} kernel\n    * @param {TensorI16} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI16}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI16);\n        _assertClass(bias, TensorI16);\n        var ret = wasm.tensori16_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI16}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI16);\n        var ret = wasm.tensori16_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI16}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori16_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI16}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensori16_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI16}\n    */\n    upsample(scales) {\n        var ret = wasm.tensori16_upsample(this.ptr, addHeapObject(scales));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @returns {TensorI16}\n    */\n    matmul(other) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_matmul(this.ptr, other.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI16} c\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI16);\n        _assertClass(c, TensorI16);\n        var ret = wasm.tensori16_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI16}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorI16);\n        var ret = wasm.tensori16_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI16}\n    */\n    reshape(shape) {\n        var ret = wasm.tensori16_reshape(this.ptr, addHeapObject(shape));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorI16} other\n    * @param {number} axes\n    * @returns {TensorI16}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorI16);\n        var ret = wasm.tensori16_concat(this.ptr, other.ptr, axes);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI16}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensori16_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI16}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensori16_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI16}\n    */\n    expand(shape) {\n        var ret = wasm.tensori16_expand(this.ptr, addHeapObject(shape));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI16}\n    */\n    copy() {\n        var ret = wasm.tensori16_copy(this.ptr);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI16}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensori16_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI16}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensori16_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI16} b\n    * @param {number} m\n    * @returns {TensorI16}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI16);\n        var ret = wasm.tensori16_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI16);\n        var ret = wasm.tensori16_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI16);\n        var ret = wasm.tensori16_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI16);\n        var ret = wasm.tensori16_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI16);\n        var ret = wasm.tensori16_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI16);\n        var ret = wasm.tensori16_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI16}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI16);\n        var ret = wasm.tensori16_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI16);\n        var ret = wasm.tensori16_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI16}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI16);\n        var ret = wasm.tensori16_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI16}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori16_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI16.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorI32 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorI32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensori32_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int32Array} values\n    * @returns {TensorI32}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensori32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI32}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensori32_create_constant(addHeapObject(shape), value);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @returns {Int32Array}\n    */\n    get_vals() {\n        var ret = wasm.tensori32_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensori32_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI32}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensori32_power_scalar(this.ptr, power, factor);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI32}\n    */\n    abs() {\n        var ret = wasm.tensori32_abs(this.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI32}\n    */\n    sign() {\n        var ret = wasm.tensori32_sign(this.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI32}\n    */\n    negate() {\n        var ret = wasm.tensori32_negate(this.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI32}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensori32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI32}\n    */\n    clip(min, max) {\n        var ret = wasm.tensori32_clip(this.ptr, min, max);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorI32}\n    */\n    clip_min(min) {\n        var ret = wasm.tensori32_clip_min(this.ptr, min);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorI32}\n    */\n    clip_max(max) {\n        var ret = wasm.tensori32_clip_max(this.ptr, max);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @returns {TensorI32}\n    */\n    power(other) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_power(this.ptr, other.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_multiply(this.ptr, other.ptr, alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_divide(this.ptr, other.ptr, alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorI32} grad\n    * @returns {TensorI32}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorI32);\n        var ret = wasm.tensori32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensori32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensori32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensori32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensori32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensori32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensori32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensori32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI32}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI32);\n        var ret = wasm.tensori32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} kernel\n    * @param {TensorI32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI32}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI32);\n        _assertClass(bias, TensorI32);\n        var ret = wasm.tensori32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI32}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI32);\n        var ret = wasm.tensori32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI32}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI32}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensori32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI32}\n    */\n    upsample(scales) {\n        var ret = wasm.tensori32_upsample(this.ptr, addHeapObject(scales));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @returns {TensorI32}\n    */\n    matmul(other) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_matmul(this.ptr, other.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI32} c\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI32);\n        _assertClass(c, TensorI32);\n        var ret = wasm.tensori32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI32}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorI32);\n        var ret = wasm.tensori32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI32}\n    */\n    reshape(shape) {\n        var ret = wasm.tensori32_reshape(this.ptr, addHeapObject(shape));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorI32} other\n    * @param {number} axes\n    * @returns {TensorI32}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorI32);\n        var ret = wasm.tensori32_concat(this.ptr, other.ptr, axes);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI32}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensori32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI32}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensori32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI32}\n    */\n    expand(shape) {\n        var ret = wasm.tensori32_expand(this.ptr, addHeapObject(shape));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI32}\n    */\n    copy() {\n        var ret = wasm.tensori32_copy(this.ptr);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI32}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensori32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI32}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensori32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI32} b\n    * @param {number} m\n    * @returns {TensorI32}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI32);\n        var ret = wasm.tensori32_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI32);\n        var ret = wasm.tensori32_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI32);\n        var ret = wasm.tensori32_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI32);\n        var ret = wasm.tensori32_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI32);\n        var ret = wasm.tensori32_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI32);\n        var ret = wasm.tensori32_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI32}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI32);\n        var ret = wasm.tensori32_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI32);\n        var ret = wasm.tensori32_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI32}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI32);\n        var ret = wasm.tensori32_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI32}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori32_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI32.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorI8 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorI8.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensori8_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Int8Array} values\n    * @returns {TensorI8}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensori8_create(addHeapObject(shape), addHeapObject(values));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorI8}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensori8_create_constant(addHeapObject(shape), value);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @returns {Int8Array}\n    */\n    get_vals() {\n        var ret = wasm.tensori8_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensori8_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorI8}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensori8_power_scalar(this.ptr, power, factor);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI8}\n    */\n    abs() {\n        var ret = wasm.tensori8_abs(this.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI8}\n    */\n    sign() {\n        var ret = wasm.tensori8_sign(this.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI8}\n    */\n    negate() {\n        var ret = wasm.tensori8_negate(this.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorI8}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensori8_add_multiply_scalar(this.ptr, factor, add);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorI8}\n    */\n    clip(min, max) {\n        var ret = wasm.tensori8_clip(this.ptr, min, max);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorI8}\n    */\n    clip_min(min) {\n        var ret = wasm.tensori8_clip_min(this.ptr, min);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorI8}\n    */\n    clip_max(max) {\n        var ret = wasm.tensori8_clip_max(this.ptr, max);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @returns {TensorI8}\n    */\n    power(other) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_power(this.ptr, other.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_multiply(this.ptr, other.ptr, alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_divide(this.ptr, other.ptr, alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorI8} grad\n    * @returns {TensorI8}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorI8);\n        var ret = wasm.tensori8_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensori8_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensori8_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensori8_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensori8_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensori8_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensori8_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensori8_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI8}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI8);\n        var ret = wasm.tensori8_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} kernel\n    * @param {TensorI8} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorI8}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorI8);\n        _assertClass(bias, TensorI8);\n        var ret = wasm.tensori8_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorI8}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorI8);\n        var ret = wasm.tensori8_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorI8}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensori8_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorI8}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensori8_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorI8}\n    */\n    upsample(scales) {\n        var ret = wasm.tensori8_upsample(this.ptr, addHeapObject(scales));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @returns {TensorI8}\n    */\n    matmul(other) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_matmul(this.ptr, other.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorI8} c\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorI8);\n        _assertClass(c, TensorI8);\n        var ret = wasm.tensori8_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} values\n    * @param {Uint32Array} starts\n    * @returns {TensorI8}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorI8);\n        var ret = wasm.tensori8_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI8}\n    */\n    reshape(shape) {\n        var ret = wasm.tensori8_reshape(this.ptr, addHeapObject(shape));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorI8} other\n    * @param {number} axes\n    * @returns {TensorI8}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorI8);\n        var ret = wasm.tensori8_concat(this.ptr, other.ptr, axes);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorI8}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensori8_transpose(this.ptr, addHeapObject(permutation));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorI8}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensori8_repeat(this.ptr, addHeapObject(repeats));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorI8}\n    */\n    expand(shape) {\n        var ret = wasm.tensori8_expand(this.ptr, addHeapObject(shape));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @returns {TensorI8}\n    */\n    copy() {\n        var ret = wasm.tensori8_copy(this.ptr);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorI8}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensori8_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorI8}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensori8_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI8} b\n    * @param {number} m\n    * @returns {TensorI8}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI8);\n        var ret = wasm.tensori8_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI8);\n        var ret = wasm.tensori8_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI8);\n        var ret = wasm.tensori8_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI8);\n        var ret = wasm.tensori8_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorI8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorI8);\n        var ret = wasm.tensori8_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI8);\n        var ret = wasm.tensori8_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorI8}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI8);\n        var ret = wasm.tensori8_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI8);\n        var ret = wasm.tensori8_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorI8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorI8}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorI8);\n        var ret = wasm.tensori8_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorI8}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensori8_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorI8.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorU16 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorU16.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensoru16_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint16Array} values\n    * @returns {TensorU16}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensoru16_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU16}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensoru16_create_constant(addHeapObject(shape), value);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @returns {Uint16Array}\n    */\n    get_vals() {\n        var ret = wasm.tensoru16_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensoru16_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU16}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensoru16_power_scalar(this.ptr, power, factor);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU16}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensoru16_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU16}\n    */\n    clip(min, max) {\n        var ret = wasm.tensoru16_clip(this.ptr, min, max);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorU16}\n    */\n    clip_min(min) {\n        var ret = wasm.tensoru16_clip_min(this.ptr, min);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorU16}\n    */\n    clip_max(max) {\n        var ret = wasm.tensoru16_clip_max(this.ptr, max);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @returns {TensorU16}\n    */\n    power(other) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_power(this.ptr, other.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_multiply(this.ptr, other.ptr, alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_divide(this.ptr, other.ptr, alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorU16} grad\n    * @returns {TensorU16}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorU16);\n        var ret = wasm.tensoru16_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensoru16_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensoru16_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensoru16_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensoru16_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensoru16_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensoru16_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensoru16_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU16}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU16);\n        var ret = wasm.tensoru16_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} kernel\n    * @param {TensorU16} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU16}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU16);\n        _assertClass(bias, TensorU16);\n        var ret = wasm.tensoru16_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU16}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU16);\n        var ret = wasm.tensoru16_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU16}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru16_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU16}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensoru16_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU16}\n    */\n    upsample(scales) {\n        var ret = wasm.tensoru16_upsample(this.ptr, addHeapObject(scales));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @returns {TensorU16}\n    */\n    matmul(other) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_matmul(this.ptr, other.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU16} c\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU16);\n        _assertClass(c, TensorU16);\n        var ret = wasm.tensoru16_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU16}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorU16);\n        var ret = wasm.tensoru16_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU16}\n    */\n    reshape(shape) {\n        var ret = wasm.tensoru16_reshape(this.ptr, addHeapObject(shape));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU16} other\n    * @param {number} axes\n    * @returns {TensorU16}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorU16);\n        var ret = wasm.tensoru16_concat(this.ptr, other.ptr, axes);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU16}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensoru16_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU16}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensoru16_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU16}\n    */\n    expand(shape) {\n        var ret = wasm.tensoru16_expand(this.ptr, addHeapObject(shape));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @returns {TensorU16}\n    */\n    copy() {\n        var ret = wasm.tensoru16_copy(this.ptr);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU16}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensoru16_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU16}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensoru16_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU16} b\n    * @param {number} m\n    * @returns {TensorU16}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU16);\n        var ret = wasm.tensoru16_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU16);\n        var ret = wasm.tensoru16_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU16);\n        var ret = wasm.tensoru16_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU16);\n        var ret = wasm.tensoru16_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU16} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU16);\n        var ret = wasm.tensoru16_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU16);\n        var ret = wasm.tensoru16_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU16}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU16);\n        var ret = wasm.tensoru16_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU16);\n        var ret = wasm.tensoru16_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU16} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU16}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU16);\n        var ret = wasm.tensoru16_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU16}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru16_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU16.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorU32 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorU32.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensoru32_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint32Array} values\n    * @returns {TensorU32}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensoru32_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU32}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensoru32_create_constant(addHeapObject(shape), value);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_vals() {\n        var ret = wasm.tensoru32_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensoru32_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU32}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensoru32_power_scalar(this.ptr, power, factor);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU32}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensoru32_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU32}\n    */\n    clip(min, max) {\n        var ret = wasm.tensoru32_clip(this.ptr, min, max);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorU32}\n    */\n    clip_min(min) {\n        var ret = wasm.tensoru32_clip_min(this.ptr, min);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorU32}\n    */\n    clip_max(max) {\n        var ret = wasm.tensoru32_clip_max(this.ptr, max);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @returns {TensorU32}\n    */\n    power(other) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_power(this.ptr, other.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_multiply(this.ptr, other.ptr, alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_divide(this.ptr, other.ptr, alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorU32} grad\n    * @returns {TensorU32}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorU32);\n        var ret = wasm.tensoru32_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensoru32_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensoru32_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensoru32_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensoru32_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensoru32_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensoru32_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensoru32_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU32}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU32);\n        var ret = wasm.tensoru32_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} kernel\n    * @param {TensorU32} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU32}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU32);\n        _assertClass(bias, TensorU32);\n        var ret = wasm.tensoru32_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU32}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU32);\n        var ret = wasm.tensoru32_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU32}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru32_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU32}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensoru32_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU32}\n    */\n    upsample(scales) {\n        var ret = wasm.tensoru32_upsample(this.ptr, addHeapObject(scales));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @returns {TensorU32}\n    */\n    matmul(other) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_matmul(this.ptr, other.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU32} c\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU32);\n        _assertClass(c, TensorU32);\n        var ret = wasm.tensoru32_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU32}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorU32);\n        var ret = wasm.tensoru32_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU32}\n    */\n    reshape(shape) {\n        var ret = wasm.tensoru32_reshape(this.ptr, addHeapObject(shape));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} other\n    * @param {number} axes\n    * @returns {TensorU32}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorU32);\n        var ret = wasm.tensoru32_concat(this.ptr, other.ptr, axes);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU32}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensoru32_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU32}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensoru32_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU32}\n    */\n    expand(shape) {\n        var ret = wasm.tensoru32_expand(this.ptr, addHeapObject(shape));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @returns {TensorU32}\n    */\n    copy() {\n        var ret = wasm.tensoru32_copy(this.ptr);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU32}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensoru32_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU32}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensoru32_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} old_sparse_shape\n    * @param {Uint32Array} new_shape\n    * @returns {TensorU32}\n    */\n    reshape_sparse_indices(old_sparse_shape, new_shape) {\n        var ret = wasm.tensoru32_reshape_sparse_indices(this.ptr, addHeapObject(old_sparse_shape), addHeapObject(new_shape));\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {number} count\n    * @returns {TensorU32}\n    */\n    add_index(axis, count) {\n        var ret = wasm.tensoru32_add_index(this.ptr, axis, count);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @param {Uint32Array} shape\n    * @param {number} repeats_prod\n    * @returns {TensorU32}\n    */\n    repeat_sparse_indices(repeats, shape, repeats_prod) {\n        var ret = wasm.tensoru32_repeat_sparse_indices(this.ptr, addHeapObject(repeats), addHeapObject(shape), repeats_prod);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b\n    * @param {number} m\n    * @returns {TensorU32}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU32);\n        var ret = wasm.tensoru32_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU32);\n        var ret = wasm.tensoru32_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU32);\n        var ret = wasm.tensoru32_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU32);\n        var ret = wasm.tensoru32_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU32);\n        var ret = wasm.tensoru32_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU32);\n        var ret = wasm.tensoru32_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU32}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU32);\n        var ret = wasm.tensoru32_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU32);\n        var ret = wasm.tensoru32_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU32} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU32}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU32);\n        var ret = wasm.tensoru32_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU32}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru32_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU32.__wrap(ret);\n    }\n}\n/**\n*/\nexport class TensorU8 {\n    static __wrap(ptr) {\n        const obj = Object.create(TensorU8.prototype);\n        obj.ptr = ptr;\n        return obj;\n    }\n    __destroy_into_raw() {\n        const ptr = this.ptr;\n        this.ptr = 0;\n        return ptr;\n    }\n    free() {\n        const ptr = this.__destroy_into_raw();\n        wasm.__wbg_tensoru8_free(ptr);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {Uint8Array} values\n    * @returns {TensorU8}\n    */\n    static create(shape, values) {\n        var ret = wasm.tensoru8_create(addHeapObject(shape), addHeapObject(values));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {number} value\n    * @returns {TensorU8}\n    */\n    static create_constant(shape, value) {\n        var ret = wasm.tensoru8_create_constant(addHeapObject(shape), value);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @returns {Uint8Array}\n    */\n    get_vals() {\n        var ret = wasm.tensoru8_get_vals(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @returns {Uint32Array}\n    */\n    get_shape() {\n        var ret = wasm.tensoru8_get_shape(this.ptr);\n        return takeObject(ret);\n    }\n    /**\n    * @param {number} power\n    * @param {number} factor\n    * @returns {TensorU8}\n    */\n    power_scalar(power, factor) {\n        var ret = wasm.tensoru8_power_scalar(this.ptr, power, factor);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} factor\n    * @param {number} add\n    * @returns {TensorU8}\n    */\n    add_multiply_scalar(factor, add) {\n        var ret = wasm.tensoru8_add_multiply_scalar(this.ptr, factor, add);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @returns {TensorU8}\n    */\n    clip(min, max) {\n        var ret = wasm.tensoru8_clip(this.ptr, min, max);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @returns {TensorU8}\n    */\n    clip_min(min) {\n        var ret = wasm.tensoru8_clip_min(this.ptr, min);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @returns {TensorU8}\n    */\n    clip_max(max) {\n        var ret = wasm.tensoru8_clip_max(this.ptr, max);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @returns {TensorU8}\n    */\n    power(other) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_power(this.ptr, other.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    addition(other, alpha, beta) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_addition(this.ptr, other.ptr, alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    subtraction(other, alpha, beta) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_subtraction(this.ptr, other.ptr, alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    multiply(other, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_multiply(this.ptr, other.ptr, alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    divide(other, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_divide(this.ptr, other.ptr, alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {number} max\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    clip_backward(min, max, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_backward(this.ptr, min, max, grad.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} min\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    clip_min_backward(min, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_min_backward(this.ptr, min, grad.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} max\n    * @param {TensorU8} grad\n    * @returns {TensorU8}\n    */\n    clip_max_backward(max, grad) {\n        _assertClass(grad, TensorU8);\n        var ret = wasm.tensoru8_clip_max_backward(this.ptr, max, grad.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    sum(axes, keep_dims) {\n        var ret = wasm.tensoru8_sum(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    sum_square(axes, keep_dims) {\n        var ret = wasm.tensoru8_sum_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    product(axes, keep_dims) {\n        var ret = wasm.tensoru8_product(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    max(axes, keep_dims) {\n        var ret = wasm.tensoru8_max(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    min(axes, keep_dims) {\n        var ret = wasm.tensoru8_min(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    reduce_mean(axes, keep_dims) {\n        var ret = wasm.tensoru8_reduce_mean(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    reduce_mean_square(axes, keep_dims) {\n        var ret = wasm.tensoru8_reduce_mean_square(this.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU8}\n    */\n    conv(kernel, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU8);\n        var ret = wasm.tensoru8_conv(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} kernel\n    * @param {TensorU8} bias\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {number} activation\n    * @returns {TensorU8}\n    */\n    conv_with_bias(kernel, bias, dilations, group, pads, strides, activation) {\n        _assertClass(kernel, TensorU8);\n        _assertClass(bias, TensorU8);\n        var ret = wasm.tensoru8_conv_with_bias(this.ptr, kernel.ptr, bias.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides), activation);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} kernel\n    * @param {Uint32Array} dilations\n    * @param {number} group\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @returns {TensorU8}\n    */\n    conv_transpose(kernel, dilations, group, pads, strides) {\n        _assertClass(kernel, TensorU8);\n        var ret = wasm.tensoru8_conv_transpose(this.ptr, kernel.ptr, addHeapObject(dilations), group, addHeapObject(pads), addHeapObject(strides));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} kernel_shape\n    * @param {Uint32Array} pads\n    * @param {Uint32Array} strides\n    * @param {boolean} include_pad\n    * @returns {TensorU8}\n    */\n    average_pool(kernel_shape, pads, strides, include_pad) {\n        var ret = wasm.tensoru8_average_pool(this.ptr, addHeapObject(kernel_shape), addHeapObject(pads), addHeapObject(strides), include_pad);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} pads\n    * @param {number} mode\n    * @param {number} value\n    * @returns {TensorU8}\n    */\n    pad(pads, mode, value) {\n        var ret = wasm.tensoru8_pad(this.ptr, addHeapObject(pads), mode, value);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Float32Array} scales\n    * @returns {TensorU8}\n    */\n    upsample(scales) {\n        var ret = wasm.tensoru8_upsample(this.ptr, addHeapObject(scales));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @returns {TensorU8}\n    */\n    matmul(other) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_matmul(this.ptr, other.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    gemm(other, a_transpose, b_transpose, alpha) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_gemm(this.ptr, other.ptr, a_transpose, b_transpose, alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {boolean} a_transpose\n    * @param {boolean} b_transpose\n    * @param {number} alpha\n    * @param {TensorU8} c\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    gemm_with_c(other, a_transpose, b_transpose, alpha, c, beta) {\n        _assertClass(other, TensorU8);\n        _assertClass(c, TensorU8);\n        var ret = wasm.tensoru8_gemm_with_c(this.ptr, other.ptr, a_transpose, b_transpose, alpha, c.ptr, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} values\n    * @param {Uint32Array} starts\n    * @returns {TensorU8}\n    */\n    set_values(values, starts) {\n        _assertClass(values, TensorU8);\n        var ret = wasm.tensoru8_set_values(this.ptr, values.ptr, addHeapObject(starts));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU8}\n    */\n    reshape(shape) {\n        var ret = wasm.tensoru8_reshape(this.ptr, addHeapObject(shape));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU8} other\n    * @param {number} axes\n    * @returns {TensorU8}\n    */\n    concat(other, axes) {\n        _assertClass(other, TensorU8);\n        var ret = wasm.tensoru8_concat(this.ptr, other.ptr, axes);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} permutation\n    * @returns {TensorU8}\n    */\n    transpose(permutation) {\n        var ret = wasm.tensoru8_transpose(this.ptr, addHeapObject(permutation));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} repeats\n    * @returns {TensorU8}\n    */\n    repeat(repeats) {\n        var ret = wasm.tensoru8_repeat(this.ptr, addHeapObject(repeats));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @returns {TensorU8}\n    */\n    expand(shape) {\n        var ret = wasm.tensoru8_expand(this.ptr, addHeapObject(shape));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @returns {TensorU8}\n    */\n    copy() {\n        var ret = wasm.tensoru8_copy(this.ptr);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {number} axis\n    * @param {Uint32Array} indices\n    * @param {Uint32Array} indice_shape\n    * @returns {TensorU8}\n    */\n    gather(axis, indices, indice_shape) {\n        var ret = wasm.tensoru8_gather(this.ptr, axis, addHeapObject(indices), addHeapObject(indice_shape));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} starts\n    * @param {Uint32Array} ends\n    * @param {Uint32Array} axis\n    * @param {Int32Array} steps\n    * @returns {TensorU8}\n    */\n    slice(starts, ends, axis, steps) {\n        var ret = wasm.tensoru8_slice(this.ptr, addHeapObject(starts), addHeapObject(ends), addHeapObject(axis), addHeapObject(steps));\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU8} b\n    * @param {number} m\n    * @returns {TensorU8}\n    */\n    matmul_sparse_dense(indices, b, m) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU8);\n        var ret = wasm.tensoru8_matmul_sparse_dense(this.ptr, indices.ptr, b.ptr, m);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    add_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU8);\n        var ret = wasm.tensoru8_add_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    subtract_sparse_dense(indices, b, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU8);\n        var ret = wasm.tensoru8_subtract_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    multiply_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU8);\n        var ret = wasm.tensoru8_multiply_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU8} b\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    divide_sparse_dense(indices, b, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b, TensorU8);\n        var ret = wasm.tensoru8_divide_sparse_dense(this.ptr, indices.ptr, b.ptr, addHeapObject(result_shape), alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    add_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU8);\n        var ret = wasm.tensoru8_add_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @param {number} beta\n    * @returns {TensorU8}\n    */\n    subtract_sparse_sparse(indices, b_indices, b_values, result_shape, alpha, beta) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU8);\n        var ret = wasm.tensoru8_subtract_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha, beta);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    divide_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU8);\n        var ret = wasm.tensoru8_divide_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {TensorU32} indices\n    * @param {TensorU32} b_indices\n    * @param {TensorU8} b_values\n    * @param {Uint32Array} result_shape\n    * @param {number} alpha\n    * @returns {TensorU8}\n    */\n    multiply_sparse_sparse(indices, b_indices, b_values, result_shape, alpha) {\n        _assertClass(indices, TensorU32);\n        _assertClass(b_indices, TensorU32);\n        _assertClass(b_values, TensorU8);\n        var ret = wasm.tensoru8_multiply_sparse_sparse(this.ptr, indices.ptr, b_indices.ptr, b_values.ptr, addHeapObject(result_shape), alpha);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    sum_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_sum_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    sum_square_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_sum_square_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    reduce_mean_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_reduce_mean_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    product_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_product_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    max_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_max_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    min_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_min_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n    /**\n    * @param {Uint32Array} shape\n    * @param {TensorU32} indices\n    * @param {Uint32Array} axes\n    * @param {boolean} keep_dims\n    * @returns {TensorU8}\n    */\n    reduce_mean_squared_sparse(shape, indices, axes, keep_dims) {\n        _assertClass(indices, TensorU32);\n        var ret = wasm.tensoru8_reduce_mean_squared_sparse(this.ptr, addHeapObject(shape), indices.ptr, addHeapObject(axes), keep_dims);\n        return TensorU8.__wrap(ret);\n    }\n}\nexport const __wbindgen_object_drop_ref = function (arg0) {\n    takeObject(arg0);\n};\nexport const __wbg_length_2db20e5652f1eb59 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_2a79df4e680048d5 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_e77849dd07b0e4b5 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_3a5138f465b971ad = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_59a5d4644faa0c8c = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_5e510700137b465e = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_c190c5ddaeb6db96 = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_length_ad7b05b022ac71bd = function (arg0) {\n    var ret = getObject(arg0).length;\n    return ret;\n};\nexport const __wbg_newwithlength_d117d423ff97cefd = function (arg0) {\n    var ret = new Int8Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_69c7c7394025c68f = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_9c30de03e0b63fdc = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_c34ef880a456cd52 = function (arg0) {\n    var ret = new Int16Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_6ef64e03d06e1433 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_85a180ecd90fa77d = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_f0f91f2b998757ae = function (arg0) {\n    var ret = new Int32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_6d504eac07f5787d = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_770ea561df838dfe = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_19241666d161c55f = function (arg0) {\n    var ret = new Uint8Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_1605a359263ce318 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_f68392bef584e583 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_2ea208e350120be9 = function (arg0) {\n    var ret = new Uint16Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_f868a054f8e08cd0 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_da0bc122908c83e4 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_03e1fd5aaabeaa27 = function (arg0) {\n    var ret = new Uint32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_6ecb10d23c5ae363 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_a0672c0ab2aa3b1c = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2 >>> 0;\n};\nexport const __wbg_newwithlength_b7a8efa36e1aa3c3 = function (arg0) {\n    var ret = new Float32Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_8ea1aa1211e70399 = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_b2937886c6ce1d95 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbg_newwithlength_b7182b9981406137 = function (arg0) {\n    var ret = new Float64Array(arg0 >>> 0);\n    return addHeapObject(ret);\n};\nexport const __wbg_getindex_b144d325ab1e7a8e = function (arg0, arg1) {\n    var ret = getObject(arg0)[arg1 >>> 0];\n    return ret;\n};\nexport const __wbg_setindex_928183e1dc113d65 = function (arg0, arg1, arg2) {\n    getObject(arg0)[arg1 >>> 0] = arg2;\n};\nexport const __wbindgen_throw = function (arg0, arg1) {\n    throw new Error(getStringFromWasm0(arg0, arg1));\n};\n//# sourceMappingURL=rust_wasm_tensor_bg.js.map","module.exports = function(originalModule) {\n\tif (!originalModule.webpackPolyfill) {\n\t\tvar module = Object.create(originalModule);\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"exports\", {\n\t\t\tenumerable: true\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n","export * from \"./rust_wasm_tensor_bg.js\";\n//# sourceMappingURL=rust_wasm_tensor.js.map"],"sourceRoot":""}